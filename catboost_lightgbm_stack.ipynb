{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc  # garbage collector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import matplotlib as mpl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pylab as pylab\n",
    "import optuna\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import utility as ut\n",
    "import importlib\n",
    "\n",
    "importlib.reload(ut)\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset - Common for both Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parcelid                       int64\n",
       "logerror                     float64\n",
       "airconditioningtypeid          int64\n",
       "architecturalstyletypeid       int64\n",
       "basementsqft                 float64\n",
       "                              ...   \n",
       "avg_area_per_room            float64\n",
       "derived_avg_area_per_room    float64\n",
       "year                           int64\n",
       "month                          int64\n",
       "quarter                        int64\n",
       "Length: 71, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_2016 = ut.load_properties_data(\"clean_data/prop_2016_clean.csv\")\n",
    "prop_2017 = ut.load_properties_data(\"clean_data/prop_2017_clean.csv\")\n",
    "train = ut.load_properties_data(\"clean_data/train_combined.csv\")\n",
    "\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for CatBoost: 55\n"
     ]
    }
   ],
   "source": [
    "# Dropping columns which do not perform well when we input to the catboost model\n",
    "catboost_features = ut.drop_features(train)\n",
    "print(\"Number of features for CatBoost: {}\".format(len(catboost_features.columns)))\n",
    "catboost_features.head(5)\n",
    "\n",
    "# Prepare feature list for catboost model\n",
    "categorical_features = [\n",
    "    \"airconditioningtypeid\",\n",
    "    \"heatingorsystemtypeid\",\n",
    "    \"propertylandusetypeid\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"quarter\",\n",
    "    \"buildingclasstypeid\",\n",
    "]\n",
    "for col in catboost_features.columns:\n",
    "    if col in categorical_features:\n",
    "        catboost_features[col] = catboost_features[col].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0276\n",
      "1   -0.1684\n",
      "2   -0.0040\n",
      "3    0.0218\n",
      "4   -0.0050\n",
      "Name: logerror, dtype: float32\n",
      "new_X: (131462, 55)\n",
      "new_y: (131462,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([['-1', 2.5, 3.0, ..., '0', '5', '2'],\n",
       "        ['0', 2.0, 4.0, ..., '1', '6', '2'],\n",
       "        ['0', 3.0, 4.0, ..., '0', '8', '3'],\n",
       "        ...,\n",
       "        ['-1', 3.0, 4.0, ..., '1', '9', '3'],\n",
       "        ['-1', 2.5, 3.0, ..., '0', '4', '2'],\n",
       "        ['0', 2.0, 4.0, ..., '1', '8', '3']], dtype=object),\n",
       " array([-0.001     , -0.02973739,  0.0315    , ..., -0.00443901,\n",
       "         0.007     ,  0.02685545], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare training and cross-validation data\n",
    "catboost_label = train.logerror.astype(np.float32)\n",
    "print(catboost_label.head())\n",
    "\n",
    "# Transform to Numpy matrices\n",
    "catboost_X = catboost_features.values\n",
    "catboost_y = catboost_label.values\n",
    "\n",
    "# Perform shuffled train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    catboost_X, catboost_y, test_size=0.2, random_state=99\n",
    ")\n",
    "ut.remove_outliers(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 13, 21, 52, 53, 54]\n"
     ]
    }
   ],
   "source": [
    "# Specify feature names and categorical features for CatBoost\n",
    "categorical_indices = ut.get_categorical_indices(\n",
    "    catboost_features, categorical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "n = [i * 0.005 for i in range(1,int(1/0.005) + 1)]\n",
    "\n",
    "# Printing the generated list\n",
    "print(len(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_X: (164299, 55)\n",
      "new_y: (164299,)\n",
      "sanity check score: 0.06857669115730533\n"
     ]
    }
   ],
   "source": [
    "ut.remove_outliers(catboost_X, catboost_y)\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(\n",
    "        loss_function=\"MAE\",\n",
    "        eval_metric=\"MAE\",\n",
    "        nan_mode=\"Min\",\n",
    "        random_seed=99,\n",
    "        iterations=1000,\n",
    "        learning_rate=0.015,\n",
    "        border_count=254,\n",
    "        max_depth=6,\n",
    "        random_strength=1,\n",
    "        l2_leaf_reg=5,\n",
    "        bagging_temperature=1,\n",
    "        verbose=True,\n",
    "    )\n",
    "model.fit(catboost_X, catboost_y, cat_features=categorical_indices, verbose=False)\n",
    "\n",
    "# Sanity check: score on a small portion of the dataset\n",
    "print(\"sanity check score: {}\".format(abs(model.predict(X_val) - y_val).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model 0 (2016)\n",
      "Start model 0 (2017)\n",
      "Length of submission DataFrame: 2985217\n",
      "Submission header:\n",
      "   ParcelId  201610  201611  201612  201710  201711  201712\n",
      "0  10754147 -0.0130 -0.0130 -0.0130 -0.0159 -0.0159 -0.0159\n",
      "1  10759547 -0.0121 -0.0121 -0.0121 -0.0121 -0.0121 -0.0121\n",
      "2  10843547  0.0040  0.0040  0.0040  0.0075  0.0075  0.0075\n",
      "3  10859147  0.0277  0.0277  0.0277  0.0293  0.0293  0.0293\n",
      "4  10879947  0.0105  0.0105  0.0105  0.0100  0.0100  0.0100\n"
     ]
    }
   ],
   "source": [
    "file_name = \"submission/final_catboost_single.csv\"\n",
    "submission, pred_2016, pred_2017 = ut.predict_and_generate_csv(\n",
    "    [model], prop_2016, prop_2017, file_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna for CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:50:33,703] A new study created in memory with name: no-name-d9aeb5b6-c00d-4d02-8bce-97c7f782c6fb\n",
      "[I 2023-11-17 15:50:37,116] Trial 0 finished with value: 0.028460523013205168 and parameters: {'iterations': 222, 'learning_rate': 0.013833811467916934, 'depth': 9, 'l2_leaf_reg': 23.933481820332084, 'border_count': 34}. Best is trial 0 with value: 0.028460523013205168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: MSE = 0.028460523013205168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:50:38,617] Trial 1 finished with value: 0.028703450130051607 and parameters: {'iterations': 56, 'learning_rate': 0.018497443241885625, 'depth': 5, 'l2_leaf_reg': 60.21798415887893, 'border_count': 184}. Best is trial 0 with value: 0.028460523013205168.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: MSE = 0.028703450130051607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:50:42,839] Trial 2 finished with value: 0.02810377943391018 and parameters: {'iterations': 193, 'learning_rate': 0.1989292856510661, 'depth': 9, 'l2_leaf_reg': 3.973009129260253, 'border_count': 174}. Best is trial 2 with value: 0.02810377943391018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3: MSE = 0.02810377943391018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:51:14,983] Trial 3 finished with value: 0.028035724909303308 and parameters: {'iterations': 637, 'learning_rate': 0.1378795807413843, 'depth': 10, 'l2_leaf_reg': 66.30510178697193, 'border_count': 215}. Best is trial 3 with value: 0.028035724909303308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4: MSE = 0.028035724909303308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:51:24,557] Trial 4 finished with value: 0.028598232366243304 and parameters: {'iterations': 260, 'learning_rate': 0.16254092269459602, 'depth': 9, 'l2_leaf_reg': 0.3843070737407729, 'border_count': 199}. Best is trial 3 with value: 0.028035724909303308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5: MSE = 0.028598232366243304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:52:03,084] Trial 5 finished with value: 0.028098251860723428 and parameters: {'iterations': 812, 'learning_rate': 0.1631927256436783, 'depth': 8, 'l2_leaf_reg': 87.95385730490297, 'border_count': 47}. Best is trial 3 with value: 0.028035724909303308.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6: MSE = 0.028098251860723428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:52:39,805] Trial 6 finished with value: 0.028024589995816935 and parameters: {'iterations': 941, 'learning_rate': 0.11746060397489776, 'depth': 6, 'l2_leaf_reg': 91.00769890378733, 'border_count': 180}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7: MSE = 0.028024589995816935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:53:08,600] Trial 7 finished with value: 0.028245610323083103 and parameters: {'iterations': 404, 'learning_rate': 0.04780748689666327, 'depth': 8, 'l2_leaf_reg': 73.16120850393627, 'border_count': 175}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8: MSE = 0.028245610323083103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:53:25,679] Trial 8 finished with value: 0.028390843669591784 and parameters: {'iterations': 633, 'learning_rate': 0.019980544195989304, 'depth': 6, 'l2_leaf_reg': 86.48817469091452, 'border_count': 69}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9: MSE = 0.028390843669591784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:53:48,226] Trial 9 finished with value: 0.028028426647290043 and parameters: {'iterations': 215, 'learning_rate': 0.14635755927730512, 'depth': 10, 'l2_leaf_reg': 23.19419378235284, 'border_count': 131}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: MSE = 0.028028426647290043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:54:10,956] Trial 10 finished with value: 0.028171461494876333 and parameters: {'iterations': 969, 'learning_rate': 0.08377055716765007, 'depth': 5, 'l2_leaf_reg': 99.53521058229754, 'border_count': 247}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11: MSE = 0.028171461494876333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:54:25,737] Trial 11 finished with value: 0.0280864780538058 and parameters: {'iterations': 421, 'learning_rate': 0.10780839901595604, 'depth': 7, 'l2_leaf_reg': 41.022188435035524, 'border_count': 113}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12: MSE = 0.0280864780538058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:54:44,270] Trial 12 finished with value: 0.028100373052852057 and parameters: {'iterations': 928, 'learning_rate': 0.11250535703146926, 'depth': 4, 'l2_leaf_reg': 44.15396958072259, 'border_count': 134}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13: MSE = 0.028100373052852057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:55:04,461] Trial 13 finished with value: 0.02806874625955379 and parameters: {'iterations': 633, 'learning_rate': 0.07588808358509005, 'depth': 7, 'l2_leaf_reg': 28.113008903184905, 'border_count': 102}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14: MSE = 0.02806874625955379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:55:09,032] Trial 14 finished with value: 0.028659620892544122 and parameters: {'iterations': 14, 'learning_rate': 0.13145471432088796, 'depth': 6, 'l2_leaf_reg': 54.710837605088095, 'border_count': 150}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15: MSE = 0.028659620892544122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:56:55,309] Trial 15 finished with value: 0.02806790371327651 and parameters: {'iterations': 783, 'learning_rate': 0.08053469268372235, 'depth': 10, 'l2_leaf_reg': 72.59076268008468, 'border_count': 143}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 16: MSE = 0.02806790371327651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:57:15,030] Trial 16 finished with value: 0.028090712869679676 and parameters: {'iterations': 509, 'learning_rate': 0.14630644180411978, 'depth': 6, 'l2_leaf_reg': 33.07100006634849, 'border_count': 99}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17: MSE = 0.028090712869679676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:57:27,702] Trial 17 finished with value: 0.02814101527790735 and parameters: {'iterations': 349, 'learning_rate': 0.12102746616920224, 'depth': 4, 'l2_leaf_reg': 16.555840929452224, 'border_count': 220}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18: MSE = 0.02814101527790735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:58:12,181] Trial 18 finished with value: 0.028081083753572968 and parameters: {'iterations': 548, 'learning_rate': 0.09729932860683857, 'depth': 8, 'l2_leaf_reg': 48.05961227600944, 'border_count': 251}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19: MSE = 0.028081083753572968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:58:20,403] Trial 19 finished with value: 0.02832961846666891 and parameters: {'iterations': 136, 'learning_rate': 0.15930866451641415, 'depth': 5, 'l2_leaf_reg': 37.70158539677041, 'border_count': 158}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20: MSE = 0.02832961846666891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 15:58:36,532] Trial 20 finished with value: 0.02812007551605706 and parameters: {'iterations': 321, 'learning_rate': 0.12306353459551349, 'depth': 7, 'l2_leaf_reg': 49.93907265723219, 'border_count': 125}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21: MSE = 0.02812007551605706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:01:23,034] Trial 21 finished with value: 0.02809544610507777 and parameters: {'iterations': 794, 'learning_rate': 0.13847797266997722, 'depth': 10, 'l2_leaf_reg': 59.2830324775364, 'border_count': 213}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22: MSE = 0.02809544610507777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:02:04,866] Trial 22 finished with value: 0.028074946626427257 and parameters: {'iterations': 636, 'learning_rate': 0.1433890708566965, 'depth': 10, 'l2_leaf_reg': 66.12024885810715, 'border_count': 227}. Best is trial 6 with value: 0.028024589995816935.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23: MSE = 0.028074946626427257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:02:46,619] Trial 23 finished with value: 0.028022388899216034 and parameters: {'iterations': 866, 'learning_rate': 0.12398893893868002, 'depth': 10, 'l2_leaf_reg': 80.11420632515885, 'border_count': 186}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24: MSE = 0.028022388899216034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:03:03,751] Trial 24 finished with value: 0.028068836027293823 and parameters: {'iterations': 897, 'learning_rate': 0.09943235019631867, 'depth': 9, 'l2_leaf_reg': 82.76936686222247, 'border_count': 192}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25: MSE = 0.028068836027293823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:03:16,487] Trial 25 finished with value: 0.028072423131694828 and parameters: {'iterations': 996, 'learning_rate': 0.1194787998408225, 'depth': 8, 'l2_leaf_reg': 98.92846143863521, 'border_count': 166}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26: MSE = 0.028072423131694828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:03:44,369] Trial 26 finished with value: 0.028105245366155395 and parameters: {'iterations': 869, 'learning_rate': 0.17808912427301085, 'depth': 10, 'l2_leaf_reg': 80.95351565536532, 'border_count': 80}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27: MSE = 0.028105245366155395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:03:59,043] Trial 27 finished with value: 0.02806399731746235 and parameters: {'iterations': 733, 'learning_rate': 0.13015620709790165, 'depth': 9, 'l2_leaf_reg': 92.18145076171116, 'border_count': 198}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 28: MSE = 0.02806399731746235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:04:07,861] Trial 28 finished with value: 0.02806226773304836 and parameters: {'iterations': 868, 'learning_rate': 0.10995121739284656, 'depth': 7, 'l2_leaf_reg': 77.63213135952446, 'border_count': 155}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29: MSE = 0.02806226773304836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:04:19,474] Trial 29 finished with value: 0.028086931593874757 and parameters: {'iterations': 701, 'learning_rate': 0.1465359107310636, 'depth': 9, 'l2_leaf_reg': 92.37041443352965, 'border_count': 127}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30: MSE = 0.028086931593874757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:04:21,951] Trial 30 finished with value: 0.028219564347506634 and parameters: {'iterations': 157, 'learning_rate': 0.12754302862022127, 'depth': 6, 'l2_leaf_reg': 19.38021875136853, 'border_count': 232}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31: MSE = 0.028219564347506634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:04:50,536] Trial 31 finished with value: 0.02809261862087938 and parameters: {'iterations': 552, 'learning_rate': 0.13862601950476502, 'depth': 10, 'l2_leaf_reg': 67.85930686285424, 'border_count': 208}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32: MSE = 0.02809261862087938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:05:22,943] Trial 32 finished with value: 0.028045577809359866 and parameters: {'iterations': 694, 'learning_rate': 0.15505463845291095, 'depth': 10, 'l2_leaf_reg': 77.10587218157261, 'border_count': 179}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 33: MSE = 0.028045577809359866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:06:08,039] Trial 33 finished with value: 0.028071513847899306 and parameters: {'iterations': 943, 'learning_rate': 0.17466138145750693, 'depth': 10, 'l2_leaf_reg': 71.56319238309695, 'border_count': 186}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34: MSE = 0.028071513847899306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:06:26,193] Trial 34 finished with value: 0.0280611597509266 and parameters: {'iterations': 847, 'learning_rate': 0.13364859794327064, 'depth': 9, 'l2_leaf_reg': 62.54289645568916, 'border_count': 238}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 35: MSE = 0.0280611597509266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:06:31,823] Trial 35 finished with value: 0.028152192581449884 and parameters: {'iterations': 236, 'learning_rate': 0.15124711131687743, 'depth': 9, 'l2_leaf_reg': 55.550118810411334, 'border_count': 203}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36: MSE = 0.028152192581449884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:06:33,697] Trial 36 finished with value: 0.028251935468251287 and parameters: {'iterations': 101, 'learning_rate': 0.1167687490112073, 'depth': 5, 'l2_leaf_reg': 8.287492126783583, 'border_count': 165}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37: MSE = 0.028251935468251287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:06:40,117] Trial 37 finished with value: 0.028045181914364076 and parameters: {'iterations': 447, 'learning_rate': 0.16929659942509, 'depth': 8, 'l2_leaf_reg': 83.83984165980246, 'border_count': 174}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38: MSE = 0.028045181914364076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:07:11,196] Trial 38 finished with value: 0.028120084960247784 and parameters: {'iterations': 769, 'learning_rate': 0.186176211162102, 'depth': 10, 'l2_leaf_reg': 76.90433360390838, 'border_count': 139}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39: MSE = 0.028120084960247784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:07:17,918] Trial 39 finished with value: 0.02810200224908139 and parameters: {'iterations': 318, 'learning_rate': 0.1594232897966545, 'depth': 9, 'l2_leaf_reg': 88.24573192113932, 'border_count': 190}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 40: MSE = 0.02810200224908139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:07:26,687] Trial 40 finished with value: 0.02804298030884857 and parameters: {'iterations': 1000, 'learning_rate': 0.15134092383765624, 'depth': 6, 'l2_leaf_reg': 67.02206308466549, 'border_count': 217}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41: MSE = 0.02804298030884857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:07:35,548] Trial 41 finished with value: 0.028092814094061166 and parameters: {'iterations': 996, 'learning_rate': 0.1378072251631479, 'depth': 6, 'l2_leaf_reg': 67.38168774132, 'border_count': 223}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 42: MSE = 0.028092814094061166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:07:42,665] Trial 42 finished with value: 0.028099761203931307 and parameters: {'iterations': 930, 'learning_rate': 0.15223259114780985, 'depth': 5, 'l2_leaf_reg': 62.91179241302973, 'border_count': 213}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43: MSE = 0.028099761203931307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:07:50,481] Trial 43 finished with value: 0.02815045554792436 and parameters: {'iterations': 844, 'learning_rate': 0.12475773573060331, 'depth': 6, 'l2_leaf_reg': 70.09267183669577, 'border_count': 244}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44: MSE = 0.02815045554792436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:08:00,124] Trial 44 finished with value: 0.0280779320272628 and parameters: {'iterations': 907, 'learning_rate': 0.16519347122334757, 'depth': 7, 'l2_leaf_reg': 74.4605148133258, 'border_count': 202}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45: MSE = 0.0280779320272628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:08:08,468] Trial 45 finished with value: 0.028087459567616727 and parameters: {'iterations': 958, 'learning_rate': 0.14320565826054815, 'depth': 6, 'l2_leaf_reg': 57.416710870891066, 'border_count': 172}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46: MSE = 0.028087459567616727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:08:14,039] Trial 46 finished with value: 0.028159644571848115 and parameters: {'iterations': 588, 'learning_rate': 0.11331015545070744, 'depth': 7, 'l2_leaf_reg': 53.32135298410331, 'border_count': 46}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 47: MSE = 0.028159644571848115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:08:21,235] Trial 47 finished with value: 0.02808365575469817 and parameters: {'iterations': 473, 'learning_rate': 0.13114198158700346, 'depth': 8, 'l2_leaf_reg': 62.52048663836281, 'border_count': 218}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 48: MSE = 0.02808365575469817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:08:26,663] Trial 48 finished with value: 0.028107633000633184 and parameters: {'iterations': 821, 'learning_rate': 0.10466350976537353, 'depth': 4, 'l2_leaf_reg': 80.33277618296705, 'border_count': 113}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49: MSE = 0.028107633000633184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-17 16:08:32,640] Trial 49 finished with value: 0.02808517140335897 and parameters: {'iterations': 739, 'learning_rate': 0.1472416360702783, 'depth': 5, 'l2_leaf_reg': 45.33447611896309, 'border_count': 235}. Best is trial 23 with value: 0.028022388899216034.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50: MSE = 0.02808517140335897\n",
      "Best Hyperparameters:\n",
      "{'iterations': 866, 'learning_rate': 0.12398893893868002, 'depth': 10, 'l2_leaf_reg': 80.11420632515885, 'border_count': 186}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to be tuned\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 10, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params, random_state=99, verbose=0)\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    mse = mean_squared_error(y_val, predictions)\n",
    "\n",
    "    print(f\"Iteration {objective.iteration}: MSE = {mse}\")\n",
    "    objective.iteration += 1\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "objective.iteration = 1\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost with 4x ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model 0\n",
      "0:\tlearn: 0.0688501\ttotal: 101ms\tremaining: 1m 40s\n",
      "1:\tlearn: 0.0688426\ttotal: 196ms\tremaining: 1m 37s\n",
      "2:\tlearn: 0.0688354\ttotal: 286ms\tremaining: 1m 34s\n",
      "3:\tlearn: 0.0688278\ttotal: 373ms\tremaining: 1m 32s\n",
      "4:\tlearn: 0.0688196\ttotal: 472ms\tremaining: 1m 33s\n",
      "5:\tlearn: 0.0688108\ttotal: 551ms\tremaining: 1m 31s\n",
      "6:\tlearn: 0.0688048\ttotal: 651ms\tremaining: 1m 32s\n",
      "7:\tlearn: 0.0687976\ttotal: 738ms\tremaining: 1m 31s\n",
      "8:\tlearn: 0.0687910\ttotal: 833ms\tremaining: 1m 31s\n",
      "9:\tlearn: 0.0687832\ttotal: 930ms\tremaining: 1m 32s\n",
      "10:\tlearn: 0.0687755\ttotal: 1.02s\tremaining: 1m 32s\n",
      "11:\tlearn: 0.0687703\ttotal: 1.13s\tremaining: 1m 32s\n",
      "12:\tlearn: 0.0687629\ttotal: 1.23s\tremaining: 1m 33s\n",
      "13:\tlearn: 0.0687561\ttotal: 1.33s\tremaining: 1m 33s\n",
      "14:\tlearn: 0.0687495\ttotal: 1.43s\tremaining: 1m 34s\n",
      "15:\tlearn: 0.0687423\ttotal: 1.53s\tremaining: 1m 34s\n",
      "16:\tlearn: 0.0687360\ttotal: 1.64s\tremaining: 1m 34s\n",
      "17:\tlearn: 0.0687310\ttotal: 1.76s\tremaining: 1m 35s\n",
      "18:\tlearn: 0.0687249\ttotal: 1.92s\tremaining: 1m 39s\n",
      "19:\tlearn: 0.0687185\ttotal: 2.03s\tremaining: 1m 39s\n",
      "20:\tlearn: 0.0687116\ttotal: 2.13s\tremaining: 1m 39s\n",
      "21:\tlearn: 0.0687068\ttotal: 2.24s\tremaining: 1m 39s\n",
      "22:\tlearn: 0.0687012\ttotal: 2.34s\tremaining: 1m 39s\n",
      "23:\tlearn: 0.0686961\ttotal: 2.45s\tremaining: 1m 39s\n",
      "24:\tlearn: 0.0686903\ttotal: 2.55s\tremaining: 1m 39s\n",
      "25:\tlearn: 0.0686858\ttotal: 2.65s\tremaining: 1m 39s\n",
      "26:\tlearn: 0.0686795\ttotal: 2.75s\tremaining: 1m 39s\n",
      "27:\tlearn: 0.0686744\ttotal: 2.86s\tremaining: 1m 39s\n",
      "28:\tlearn: 0.0686689\ttotal: 2.96s\tremaining: 1m 38s\n",
      "29:\tlearn: 0.0686635\ttotal: 3.06s\tremaining: 1m 38s\n",
      "30:\tlearn: 0.0686586\ttotal: 3.17s\tremaining: 1m 39s\n",
      "31:\tlearn: 0.0686532\ttotal: 3.28s\tremaining: 1m 39s\n",
      "32:\tlearn: 0.0686478\ttotal: 3.36s\tremaining: 1m 38s\n",
      "33:\tlearn: 0.0686431\ttotal: 3.48s\tremaining: 1m 39s\n",
      "34:\tlearn: 0.0686376\ttotal: 3.59s\tremaining: 1m 39s\n",
      "35:\tlearn: 0.0686325\ttotal: 3.71s\tremaining: 1m 39s\n",
      "36:\tlearn: 0.0686276\ttotal: 3.82s\tremaining: 1m 39s\n",
      "37:\tlearn: 0.0686231\ttotal: 3.92s\tremaining: 1m 39s\n",
      "38:\tlearn: 0.0686182\ttotal: 4.03s\tremaining: 1m 39s\n",
      "39:\tlearn: 0.0686134\ttotal: 4.12s\tremaining: 1m 38s\n",
      "40:\tlearn: 0.0686095\ttotal: 4.22s\tremaining: 1m 38s\n",
      "41:\tlearn: 0.0686054\ttotal: 4.32s\tremaining: 1m 38s\n",
      "42:\tlearn: 0.0686017\ttotal: 4.43s\tremaining: 1m 38s\n",
      "43:\tlearn: 0.0685978\ttotal: 4.53s\tremaining: 1m 38s\n",
      "44:\tlearn: 0.0685943\ttotal: 4.62s\tremaining: 1m 38s\n",
      "45:\tlearn: 0.0685909\ttotal: 4.73s\tremaining: 1m 38s\n",
      "46:\tlearn: 0.0685869\ttotal: 4.84s\tremaining: 1m 38s\n",
      "47:\tlearn: 0.0685828\ttotal: 4.97s\tremaining: 1m 38s\n",
      "48:\tlearn: 0.0685788\ttotal: 5.08s\tremaining: 1m 38s\n",
      "49:\tlearn: 0.0685747\ttotal: 5.21s\tremaining: 1m 39s\n",
      "50:\tlearn: 0.0685716\ttotal: 5.32s\tremaining: 1m 38s\n",
      "51:\tlearn: 0.0685674\ttotal: 5.42s\tremaining: 1m 38s\n",
      "52:\tlearn: 0.0685643\ttotal: 5.53s\tremaining: 1m 38s\n",
      "53:\tlearn: 0.0685608\ttotal: 5.64s\tremaining: 1m 38s\n",
      "54:\tlearn: 0.0685579\ttotal: 5.74s\tremaining: 1m 38s\n",
      "55:\tlearn: 0.0685545\ttotal: 5.86s\tremaining: 1m 38s\n",
      "56:\tlearn: 0.0685511\ttotal: 5.96s\tremaining: 1m 38s\n",
      "57:\tlearn: 0.0685481\ttotal: 6.08s\tremaining: 1m 38s\n",
      "58:\tlearn: 0.0685449\ttotal: 6.18s\tremaining: 1m 38s\n",
      "59:\tlearn: 0.0685418\ttotal: 6.29s\tremaining: 1m 38s\n",
      "60:\tlearn: 0.0685377\ttotal: 6.38s\tremaining: 1m 38s\n",
      "61:\tlearn: 0.0685344\ttotal: 6.51s\tremaining: 1m 38s\n",
      "62:\tlearn: 0.0685307\ttotal: 6.63s\tremaining: 1m 38s\n",
      "63:\tlearn: 0.0685269\ttotal: 6.72s\tremaining: 1m 38s\n",
      "64:\tlearn: 0.0685237\ttotal: 6.82s\tremaining: 1m 38s\n",
      "65:\tlearn: 0.0685197\ttotal: 6.93s\tremaining: 1m 38s\n",
      "66:\tlearn: 0.0685158\ttotal: 7.03s\tremaining: 1m 37s\n",
      "67:\tlearn: 0.0685127\ttotal: 7.12s\tremaining: 1m 37s\n",
      "68:\tlearn: 0.0685099\ttotal: 7.25s\tremaining: 1m 37s\n",
      "69:\tlearn: 0.0685067\ttotal: 7.35s\tremaining: 1m 37s\n",
      "70:\tlearn: 0.0685041\ttotal: 7.44s\tremaining: 1m 37s\n",
      "71:\tlearn: 0.0685018\ttotal: 7.54s\tremaining: 1m 37s\n",
      "72:\tlearn: 0.0684997\ttotal: 7.64s\tremaining: 1m 37s\n",
      "73:\tlearn: 0.0684965\ttotal: 7.75s\tremaining: 1m 36s\n",
      "74:\tlearn: 0.0684942\ttotal: 7.85s\tremaining: 1m 36s\n",
      "75:\tlearn: 0.0684915\ttotal: 7.94s\tremaining: 1m 36s\n",
      "76:\tlearn: 0.0684888\ttotal: 8.06s\tremaining: 1m 36s\n",
      "77:\tlearn: 0.0684854\ttotal: 8.16s\tremaining: 1m 36s\n",
      "78:\tlearn: 0.0684825\ttotal: 8.26s\tremaining: 1m 36s\n",
      "79:\tlearn: 0.0684793\ttotal: 8.35s\tremaining: 1m 36s\n",
      "80:\tlearn: 0.0684769\ttotal: 8.45s\tremaining: 1m 35s\n",
      "81:\tlearn: 0.0684743\ttotal: 8.55s\tremaining: 1m 35s\n",
      "82:\tlearn: 0.0684717\ttotal: 8.63s\tremaining: 1m 35s\n",
      "83:\tlearn: 0.0684689\ttotal: 8.73s\tremaining: 1m 35s\n",
      "84:\tlearn: 0.0684665\ttotal: 8.84s\tremaining: 1m 35s\n",
      "85:\tlearn: 0.0684638\ttotal: 8.94s\tremaining: 1m 34s\n",
      "86:\tlearn: 0.0684616\ttotal: 9.04s\tremaining: 1m 34s\n",
      "87:\tlearn: 0.0684592\ttotal: 9.16s\tremaining: 1m 34s\n",
      "88:\tlearn: 0.0684567\ttotal: 9.26s\tremaining: 1m 34s\n",
      "89:\tlearn: 0.0684538\ttotal: 9.34s\tremaining: 1m 34s\n",
      "90:\tlearn: 0.0684515\ttotal: 9.44s\tremaining: 1m 34s\n",
      "91:\tlearn: 0.0684492\ttotal: 9.54s\tremaining: 1m 34s\n",
      "92:\tlearn: 0.0684467\ttotal: 9.64s\tremaining: 1m 34s\n",
      "93:\tlearn: 0.0684434\ttotal: 9.74s\tremaining: 1m 33s\n",
      "94:\tlearn: 0.0684412\ttotal: 9.85s\tremaining: 1m 33s\n",
      "95:\tlearn: 0.0684387\ttotal: 9.94s\tremaining: 1m 33s\n",
      "96:\tlearn: 0.0684362\ttotal: 10.1s\tremaining: 1m 33s\n",
      "97:\tlearn: 0.0684344\ttotal: 10.1s\tremaining: 1m 33s\n",
      "98:\tlearn: 0.0684320\ttotal: 10.2s\tremaining: 1m 33s\n",
      "99:\tlearn: 0.0684297\ttotal: 10.3s\tremaining: 1m 33s\n",
      "100:\tlearn: 0.0684271\ttotal: 10.4s\tremaining: 1m 32s\n",
      "101:\tlearn: 0.0684248\ttotal: 10.5s\tremaining: 1m 32s\n",
      "102:\tlearn: 0.0684230\ttotal: 10.6s\tremaining: 1m 32s\n",
      "103:\tlearn: 0.0684210\ttotal: 10.8s\tremaining: 1m 32s\n",
      "104:\tlearn: 0.0684186\ttotal: 10.9s\tremaining: 1m 32s\n",
      "105:\tlearn: 0.0684165\ttotal: 11s\tremaining: 1m 32s\n",
      "106:\tlearn: 0.0684142\ttotal: 11.1s\tremaining: 1m 32s\n",
      "107:\tlearn: 0.0684120\ttotal: 11.2s\tremaining: 1m 32s\n",
      "108:\tlearn: 0.0684105\ttotal: 11.3s\tremaining: 1m 32s\n",
      "109:\tlearn: 0.0684087\ttotal: 11.4s\tremaining: 1m 32s\n",
      "110:\tlearn: 0.0684057\ttotal: 11.5s\tremaining: 1m 32s\n",
      "111:\tlearn: 0.0684037\ttotal: 11.6s\tremaining: 1m 31s\n",
      "112:\tlearn: 0.0684013\ttotal: 11.7s\tremaining: 1m 31s\n",
      "113:\tlearn: 0.0683985\ttotal: 11.8s\tremaining: 1m 31s\n",
      "114:\tlearn: 0.0683957\ttotal: 11.9s\tremaining: 1m 31s\n",
      "115:\tlearn: 0.0683942\ttotal: 12s\tremaining: 1m 31s\n",
      "116:\tlearn: 0.0683913\ttotal: 12.1s\tremaining: 1m 31s\n",
      "117:\tlearn: 0.0683896\ttotal: 12.2s\tremaining: 1m 31s\n",
      "118:\tlearn: 0.0683873\ttotal: 12.3s\tremaining: 1m 30s\n",
      "119:\tlearn: 0.0683848\ttotal: 12.4s\tremaining: 1m 30s\n",
      "120:\tlearn: 0.0683831\ttotal: 12.5s\tremaining: 1m 30s\n",
      "121:\tlearn: 0.0683817\ttotal: 12.6s\tremaining: 1m 30s\n",
      "122:\tlearn: 0.0683795\ttotal: 12.6s\tremaining: 1m 30s\n",
      "123:\tlearn: 0.0683773\ttotal: 12.7s\tremaining: 1m 30s\n",
      "124:\tlearn: 0.0683758\ttotal: 12.8s\tremaining: 1m 29s\n",
      "125:\tlearn: 0.0683736\ttotal: 12.9s\tremaining: 1m 29s\n",
      "126:\tlearn: 0.0683718\ttotal: 13.1s\tremaining: 1m 29s\n",
      "127:\tlearn: 0.0683704\ttotal: 13.2s\tremaining: 1m 29s\n",
      "128:\tlearn: 0.0683682\ttotal: 13.3s\tremaining: 1m 29s\n",
      "129:\tlearn: 0.0683656\ttotal: 13.4s\tremaining: 1m 29s\n",
      "130:\tlearn: 0.0683640\ttotal: 13.5s\tremaining: 1m 29s\n",
      "131:\tlearn: 0.0683624\ttotal: 13.6s\tremaining: 1m 29s\n",
      "132:\tlearn: 0.0683605\ttotal: 13.7s\tremaining: 1m 29s\n",
      "133:\tlearn: 0.0683590\ttotal: 13.8s\tremaining: 1m 29s\n",
      "134:\tlearn: 0.0683576\ttotal: 14s\tremaining: 1m 29s\n",
      "135:\tlearn: 0.0683560\ttotal: 14.1s\tremaining: 1m 29s\n",
      "136:\tlearn: 0.0683545\ttotal: 14.2s\tremaining: 1m 29s\n",
      "137:\tlearn: 0.0683527\ttotal: 14.3s\tremaining: 1m 29s\n",
      "138:\tlearn: 0.0683508\ttotal: 14.4s\tremaining: 1m 29s\n",
      "139:\tlearn: 0.0683487\ttotal: 14.5s\tremaining: 1m 29s\n",
      "140:\tlearn: 0.0683472\ttotal: 14.6s\tremaining: 1m 28s\n",
      "141:\tlearn: 0.0683450\ttotal: 14.7s\tremaining: 1m 28s\n",
      "142:\tlearn: 0.0683432\ttotal: 14.8s\tremaining: 1m 28s\n",
      "143:\tlearn: 0.0683414\ttotal: 14.9s\tremaining: 1m 28s\n",
      "144:\tlearn: 0.0683398\ttotal: 15s\tremaining: 1m 28s\n",
      "145:\tlearn: 0.0683383\ttotal: 15.1s\tremaining: 1m 28s\n",
      "146:\tlearn: 0.0683369\ttotal: 15.2s\tremaining: 1m 28s\n",
      "147:\tlearn: 0.0683354\ttotal: 15.4s\tremaining: 1m 28s\n",
      "148:\tlearn: 0.0683335\ttotal: 15.5s\tremaining: 1m 28s\n",
      "149:\tlearn: 0.0683322\ttotal: 15.6s\tremaining: 1m 28s\n",
      "150:\tlearn: 0.0683305\ttotal: 15.7s\tremaining: 1m 28s\n",
      "151:\tlearn: 0.0683294\ttotal: 15.8s\tremaining: 1m 28s\n",
      "152:\tlearn: 0.0683271\ttotal: 15.9s\tremaining: 1m 28s\n",
      "153:\tlearn: 0.0683253\ttotal: 16s\tremaining: 1m 28s\n",
      "154:\tlearn: 0.0683240\ttotal: 16.1s\tremaining: 1m 27s\n",
      "155:\tlearn: 0.0683225\ttotal: 16.2s\tremaining: 1m 27s\n",
      "156:\tlearn: 0.0683213\ttotal: 16.3s\tremaining: 1m 27s\n",
      "157:\tlearn: 0.0683201\ttotal: 16.4s\tremaining: 1m 27s\n",
      "158:\tlearn: 0.0683189\ttotal: 16.5s\tremaining: 1m 27s\n",
      "159:\tlearn: 0.0683176\ttotal: 16.6s\tremaining: 1m 27s\n",
      "160:\tlearn: 0.0683166\ttotal: 16.7s\tremaining: 1m 27s\n",
      "161:\tlearn: 0.0683150\ttotal: 16.8s\tremaining: 1m 27s\n",
      "162:\tlearn: 0.0683129\ttotal: 16.9s\tremaining: 1m 26s\n",
      "163:\tlearn: 0.0683117\ttotal: 17s\tremaining: 1m 26s\n",
      "164:\tlearn: 0.0683098\ttotal: 17.1s\tremaining: 1m 26s\n",
      "165:\tlearn: 0.0683076\ttotal: 17.2s\tremaining: 1m 26s\n",
      "166:\tlearn: 0.0683063\ttotal: 17.3s\tremaining: 1m 26s\n",
      "167:\tlearn: 0.0683051\ttotal: 17.4s\tremaining: 1m 26s\n",
      "168:\tlearn: 0.0683032\ttotal: 17.5s\tremaining: 1m 26s\n",
      "169:\tlearn: 0.0683021\ttotal: 17.6s\tremaining: 1m 26s\n",
      "170:\tlearn: 0.0683001\ttotal: 17.7s\tremaining: 1m 26s\n",
      "171:\tlearn: 0.0682987\ttotal: 17.8s\tremaining: 1m 25s\n",
      "172:\tlearn: 0.0682975\ttotal: 17.9s\tremaining: 1m 25s\n",
      "173:\tlearn: 0.0682966\ttotal: 18s\tremaining: 1m 25s\n",
      "174:\tlearn: 0.0682946\ttotal: 18.1s\tremaining: 1m 25s\n",
      "175:\tlearn: 0.0682920\ttotal: 18.3s\tremaining: 1m 25s\n",
      "176:\tlearn: 0.0682904\ttotal: 18.4s\tremaining: 1m 25s\n",
      "177:\tlearn: 0.0682889\ttotal: 18.5s\tremaining: 1m 25s\n",
      "178:\tlearn: 0.0682878\ttotal: 18.6s\tremaining: 1m 25s\n",
      "179:\tlearn: 0.0682860\ttotal: 18.7s\tremaining: 1m 25s\n",
      "180:\tlearn: 0.0682840\ttotal: 18.8s\tremaining: 1m 25s\n",
      "181:\tlearn: 0.0682829\ttotal: 18.9s\tremaining: 1m 25s\n",
      "182:\tlearn: 0.0682817\ttotal: 19s\tremaining: 1m 24s\n",
      "183:\tlearn: 0.0682797\ttotal: 19.1s\tremaining: 1m 24s\n",
      "184:\tlearn: 0.0682782\ttotal: 19.2s\tremaining: 1m 24s\n",
      "185:\tlearn: 0.0682768\ttotal: 19.3s\tremaining: 1m 24s\n",
      "186:\tlearn: 0.0682753\ttotal: 19.4s\tremaining: 1m 24s\n",
      "187:\tlearn: 0.0682740\ttotal: 19.5s\tremaining: 1m 24s\n",
      "188:\tlearn: 0.0682725\ttotal: 19.6s\tremaining: 1m 24s\n",
      "189:\tlearn: 0.0682704\ttotal: 19.7s\tremaining: 1m 24s\n",
      "190:\tlearn: 0.0682693\ttotal: 19.8s\tremaining: 1m 23s\n",
      "191:\tlearn: 0.0682681\ttotal: 19.9s\tremaining: 1m 23s\n",
      "192:\tlearn: 0.0682660\ttotal: 20s\tremaining: 1m 23s\n",
      "193:\tlearn: 0.0682649\ttotal: 20.2s\tremaining: 1m 23s\n",
      "194:\tlearn: 0.0682637\ttotal: 20.3s\tremaining: 1m 23s\n",
      "195:\tlearn: 0.0682619\ttotal: 20.4s\tremaining: 1m 23s\n",
      "196:\tlearn: 0.0682604\ttotal: 20.5s\tremaining: 1m 23s\n",
      "197:\tlearn: 0.0682592\ttotal: 20.6s\tremaining: 1m 23s\n",
      "198:\tlearn: 0.0682580\ttotal: 20.7s\tremaining: 1m 23s\n",
      "199:\tlearn: 0.0682564\ttotal: 20.8s\tremaining: 1m 23s\n",
      "200:\tlearn: 0.0682548\ttotal: 20.9s\tremaining: 1m 23s\n",
      "201:\tlearn: 0.0682536\ttotal: 21s\tremaining: 1m 23s\n",
      "202:\tlearn: 0.0682523\ttotal: 21.1s\tremaining: 1m 22s\n",
      "203:\tlearn: 0.0682511\ttotal: 21.2s\tremaining: 1m 22s\n",
      "204:\tlearn: 0.0682499\ttotal: 21.4s\tremaining: 1m 22s\n",
      "205:\tlearn: 0.0682489\ttotal: 21.5s\tremaining: 1m 22s\n",
      "206:\tlearn: 0.0682472\ttotal: 21.6s\tremaining: 1m 22s\n",
      "207:\tlearn: 0.0682460\ttotal: 21.7s\tremaining: 1m 22s\n",
      "208:\tlearn: 0.0682449\ttotal: 21.8s\tremaining: 1m 22s\n",
      "209:\tlearn: 0.0682441\ttotal: 21.9s\tremaining: 1m 22s\n",
      "210:\tlearn: 0.0682429\ttotal: 22s\tremaining: 1m 22s\n",
      "211:\tlearn: 0.0682412\ttotal: 22.1s\tremaining: 1m 22s\n",
      "212:\tlearn: 0.0682388\ttotal: 22.2s\tremaining: 1m 22s\n",
      "213:\tlearn: 0.0682372\ttotal: 22.3s\tremaining: 1m 22s\n",
      "214:\tlearn: 0.0682358\ttotal: 22.4s\tremaining: 1m 21s\n",
      "215:\tlearn: 0.0682337\ttotal: 22.6s\tremaining: 1m 21s\n",
      "216:\tlearn: 0.0682318\ttotal: 22.7s\tremaining: 1m 21s\n",
      "217:\tlearn: 0.0682307\ttotal: 22.8s\tremaining: 1m 21s\n",
      "218:\tlearn: 0.0682292\ttotal: 22.9s\tremaining: 1m 21s\n",
      "219:\tlearn: 0.0682277\ttotal: 23s\tremaining: 1m 21s\n",
      "220:\tlearn: 0.0682268\ttotal: 23.1s\tremaining: 1m 21s\n",
      "221:\tlearn: 0.0682258\ttotal: 23.2s\tremaining: 1m 21s\n",
      "222:\tlearn: 0.0682246\ttotal: 23.3s\tremaining: 1m 21s\n",
      "223:\tlearn: 0.0682234\ttotal: 23.4s\tremaining: 1m 21s\n",
      "224:\tlearn: 0.0682223\ttotal: 23.5s\tremaining: 1m 21s\n",
      "225:\tlearn: 0.0682215\ttotal: 23.6s\tremaining: 1m 20s\n",
      "226:\tlearn: 0.0682201\ttotal: 23.7s\tremaining: 1m 20s\n",
      "227:\tlearn: 0.0682189\ttotal: 23.9s\tremaining: 1m 20s\n",
      "228:\tlearn: 0.0682181\ttotal: 24s\tremaining: 1m 20s\n",
      "229:\tlearn: 0.0682170\ttotal: 24.1s\tremaining: 1m 20s\n",
      "230:\tlearn: 0.0682158\ttotal: 24.2s\tremaining: 1m 20s\n",
      "231:\tlearn: 0.0682142\ttotal: 24.3s\tremaining: 1m 20s\n",
      "232:\tlearn: 0.0682128\ttotal: 24.4s\tremaining: 1m 20s\n",
      "233:\tlearn: 0.0682113\ttotal: 24.5s\tremaining: 1m 20s\n",
      "234:\tlearn: 0.0682100\ttotal: 24.6s\tremaining: 1m 20s\n",
      "235:\tlearn: 0.0682087\ttotal: 24.7s\tremaining: 1m 20s\n",
      "236:\tlearn: 0.0682072\ttotal: 24.9s\tremaining: 1m 20s\n",
      "237:\tlearn: 0.0682057\ttotal: 25s\tremaining: 1m 19s\n",
      "238:\tlearn: 0.0682043\ttotal: 25.1s\tremaining: 1m 19s\n",
      "239:\tlearn: 0.0682028\ttotal: 25.2s\tremaining: 1m 19s\n",
      "240:\tlearn: 0.0682013\ttotal: 25.3s\tremaining: 1m 19s\n",
      "241:\tlearn: 0.0682003\ttotal: 25.4s\tremaining: 1m 19s\n",
      "242:\tlearn: 0.0681990\ttotal: 25.5s\tremaining: 1m 19s\n",
      "243:\tlearn: 0.0681981\ttotal: 25.6s\tremaining: 1m 19s\n",
      "244:\tlearn: 0.0681967\ttotal: 25.7s\tremaining: 1m 19s\n",
      "245:\tlearn: 0.0681955\ttotal: 25.8s\tremaining: 1m 19s\n",
      "246:\tlearn: 0.0681939\ttotal: 25.9s\tremaining: 1m 18s\n",
      "247:\tlearn: 0.0681923\ttotal: 26s\tremaining: 1m 18s\n",
      "248:\tlearn: 0.0681912\ttotal: 26.1s\tremaining: 1m 18s\n",
      "249:\tlearn: 0.0681899\ttotal: 26.2s\tremaining: 1m 18s\n",
      "250:\tlearn: 0.0681890\ttotal: 26.3s\tremaining: 1m 18s\n",
      "251:\tlearn: 0.0681880\ttotal: 26.4s\tremaining: 1m 18s\n",
      "252:\tlearn: 0.0681864\ttotal: 26.5s\tremaining: 1m 18s\n",
      "253:\tlearn: 0.0681851\ttotal: 26.7s\tremaining: 1m 18s\n",
      "254:\tlearn: 0.0681836\ttotal: 26.8s\tremaining: 1m 18s\n",
      "255:\tlearn: 0.0681827\ttotal: 26.9s\tremaining: 1m 18s\n",
      "256:\tlearn: 0.0681817\ttotal: 27s\tremaining: 1m 18s\n",
      "257:\tlearn: 0.0681796\ttotal: 27.1s\tremaining: 1m 17s\n",
      "258:\tlearn: 0.0681784\ttotal: 27.2s\tremaining: 1m 17s\n",
      "259:\tlearn: 0.0681770\ttotal: 27.3s\tremaining: 1m 17s\n",
      "260:\tlearn: 0.0681757\ttotal: 27.4s\tremaining: 1m 17s\n",
      "261:\tlearn: 0.0681749\ttotal: 27.5s\tremaining: 1m 17s\n",
      "262:\tlearn: 0.0681740\ttotal: 27.6s\tremaining: 1m 17s\n",
      "263:\tlearn: 0.0681719\ttotal: 27.7s\tremaining: 1m 17s\n",
      "264:\tlearn: 0.0681709\ttotal: 27.8s\tremaining: 1m 17s\n",
      "265:\tlearn: 0.0681699\ttotal: 27.9s\tremaining: 1m 17s\n",
      "266:\tlearn: 0.0681682\ttotal: 28s\tremaining: 1m 16s\n",
      "267:\tlearn: 0.0681670\ttotal: 28.1s\tremaining: 1m 16s\n",
      "268:\tlearn: 0.0681657\ttotal: 28.2s\tremaining: 1m 16s\n",
      "269:\tlearn: 0.0681647\ttotal: 28.3s\tremaining: 1m 16s\n",
      "270:\tlearn: 0.0681638\ttotal: 28.4s\tremaining: 1m 16s\n",
      "271:\tlearn: 0.0681620\ttotal: 28.6s\tremaining: 1m 16s\n",
      "272:\tlearn: 0.0681609\ttotal: 28.7s\tremaining: 1m 16s\n",
      "273:\tlearn: 0.0681598\ttotal: 28.8s\tremaining: 1m 16s\n",
      "274:\tlearn: 0.0681588\ttotal: 28.9s\tremaining: 1m 16s\n",
      "275:\tlearn: 0.0681579\ttotal: 29s\tremaining: 1m 16s\n",
      "276:\tlearn: 0.0681570\ttotal: 29.1s\tremaining: 1m 15s\n",
      "277:\tlearn: 0.0681558\ttotal: 29.2s\tremaining: 1m 15s\n",
      "278:\tlearn: 0.0681552\ttotal: 29.3s\tremaining: 1m 15s\n",
      "279:\tlearn: 0.0681540\ttotal: 29.4s\tremaining: 1m 15s\n",
      "280:\tlearn: 0.0681529\ttotal: 29.5s\tremaining: 1m 15s\n",
      "281:\tlearn: 0.0681516\ttotal: 29.6s\tremaining: 1m 15s\n",
      "282:\tlearn: 0.0681500\ttotal: 29.7s\tremaining: 1m 15s\n",
      "283:\tlearn: 0.0681489\ttotal: 29.8s\tremaining: 1m 15s\n",
      "284:\tlearn: 0.0681478\ttotal: 29.9s\tremaining: 1m 14s\n",
      "285:\tlearn: 0.0681472\ttotal: 30s\tremaining: 1m 14s\n",
      "286:\tlearn: 0.0681463\ttotal: 30.1s\tremaining: 1m 14s\n",
      "287:\tlearn: 0.0681451\ttotal: 30.2s\tremaining: 1m 14s\n",
      "288:\tlearn: 0.0681443\ttotal: 30.3s\tremaining: 1m 14s\n",
      "289:\tlearn: 0.0681426\ttotal: 30.4s\tremaining: 1m 14s\n",
      "290:\tlearn: 0.0681419\ttotal: 30.5s\tremaining: 1m 14s\n",
      "291:\tlearn: 0.0681412\ttotal: 30.6s\tremaining: 1m 14s\n",
      "292:\tlearn: 0.0681405\ttotal: 30.7s\tremaining: 1m 13s\n",
      "293:\tlearn: 0.0681392\ttotal: 30.7s\tremaining: 1m 13s\n",
      "294:\tlearn: 0.0681386\ttotal: 30.8s\tremaining: 1m 13s\n",
      "295:\tlearn: 0.0681376\ttotal: 30.9s\tremaining: 1m 13s\n",
      "296:\tlearn: 0.0681365\ttotal: 31.1s\tremaining: 1m 13s\n",
      "297:\tlearn: 0.0681351\ttotal: 31.2s\tremaining: 1m 13s\n",
      "298:\tlearn: 0.0681345\ttotal: 31.2s\tremaining: 1m 13s\n",
      "299:\tlearn: 0.0681339\ttotal: 31.3s\tremaining: 1m 13s\n",
      "300:\tlearn: 0.0681332\ttotal: 31.4s\tremaining: 1m 12s\n",
      "301:\tlearn: 0.0681323\ttotal: 31.5s\tremaining: 1m 12s\n",
      "302:\tlearn: 0.0681310\ttotal: 31.7s\tremaining: 1m 12s\n",
      "303:\tlearn: 0.0681303\ttotal: 31.8s\tremaining: 1m 12s\n",
      "304:\tlearn: 0.0681294\ttotal: 31.8s\tremaining: 1m 12s\n",
      "305:\tlearn: 0.0681276\ttotal: 32s\tremaining: 1m 12s\n",
      "306:\tlearn: 0.0681267\ttotal: 32.1s\tremaining: 1m 12s\n",
      "307:\tlearn: 0.0681261\ttotal: 32.1s\tremaining: 1m 12s\n",
      "308:\tlearn: 0.0681254\ttotal: 32.2s\tremaining: 1m 12s\n",
      "309:\tlearn: 0.0681240\ttotal: 32.3s\tremaining: 1m 11s\n",
      "310:\tlearn: 0.0681233\ttotal: 32.4s\tremaining: 1m 11s\n",
      "311:\tlearn: 0.0681221\ttotal: 32.5s\tremaining: 1m 11s\n",
      "312:\tlearn: 0.0681212\ttotal: 32.7s\tremaining: 1m 11s\n",
      "313:\tlearn: 0.0681203\ttotal: 32.7s\tremaining: 1m 11s\n",
      "314:\tlearn: 0.0681193\ttotal: 32.9s\tremaining: 1m 11s\n",
      "315:\tlearn: 0.0681186\ttotal: 33s\tremaining: 1m 11s\n",
      "316:\tlearn: 0.0681168\ttotal: 33.1s\tremaining: 1m 11s\n",
      "317:\tlearn: 0.0681164\ttotal: 33.2s\tremaining: 1m 11s\n",
      "318:\tlearn: 0.0681157\ttotal: 33.3s\tremaining: 1m 11s\n",
      "319:\tlearn: 0.0681146\ttotal: 33.4s\tremaining: 1m 10s\n",
      "320:\tlearn: 0.0681135\ttotal: 33.4s\tremaining: 1m 10s\n",
      "321:\tlearn: 0.0681125\ttotal: 33.5s\tremaining: 1m 10s\n",
      "322:\tlearn: 0.0681118\ttotal: 33.7s\tremaining: 1m 10s\n",
      "323:\tlearn: 0.0681109\ttotal: 33.8s\tremaining: 1m 10s\n",
      "324:\tlearn: 0.0681104\ttotal: 33.9s\tremaining: 1m 10s\n",
      "325:\tlearn: 0.0681092\ttotal: 34s\tremaining: 1m 10s\n",
      "326:\tlearn: 0.0681084\ttotal: 34.1s\tremaining: 1m 10s\n",
      "327:\tlearn: 0.0681070\ttotal: 34.2s\tremaining: 1m 9s\n",
      "328:\tlearn: 0.0681058\ttotal: 34.3s\tremaining: 1m 9s\n",
      "329:\tlearn: 0.0681050\ttotal: 34.4s\tremaining: 1m 9s\n",
      "330:\tlearn: 0.0681034\ttotal: 34.5s\tremaining: 1m 9s\n",
      "331:\tlearn: 0.0681021\ttotal: 34.6s\tremaining: 1m 9s\n",
      "332:\tlearn: 0.0681011\ttotal: 34.7s\tremaining: 1m 9s\n",
      "333:\tlearn: 0.0681006\ttotal: 34.8s\tremaining: 1m 9s\n",
      "334:\tlearn: 0.0681000\ttotal: 34.9s\tremaining: 1m 9s\n",
      "335:\tlearn: 0.0680993\ttotal: 35s\tremaining: 1m 9s\n",
      "336:\tlearn: 0.0680980\ttotal: 35.1s\tremaining: 1m 8s\n",
      "337:\tlearn: 0.0680970\ttotal: 35.2s\tremaining: 1m 8s\n",
      "338:\tlearn: 0.0680966\ttotal: 35.3s\tremaining: 1m 8s\n",
      "339:\tlearn: 0.0680956\ttotal: 35.4s\tremaining: 1m 8s\n",
      "340:\tlearn: 0.0680947\ttotal: 35.5s\tremaining: 1m 8s\n",
      "341:\tlearn: 0.0680931\ttotal: 35.6s\tremaining: 1m 8s\n",
      "342:\tlearn: 0.0680918\ttotal: 35.7s\tremaining: 1m 8s\n",
      "343:\tlearn: 0.0680911\ttotal: 35.8s\tremaining: 1m 8s\n",
      "344:\tlearn: 0.0680900\ttotal: 35.9s\tremaining: 1m 8s\n",
      "345:\tlearn: 0.0680891\ttotal: 36s\tremaining: 1m 8s\n",
      "346:\tlearn: 0.0680887\ttotal: 36.1s\tremaining: 1m 7s\n",
      "347:\tlearn: 0.0680876\ttotal: 36.2s\tremaining: 1m 7s\n",
      "348:\tlearn: 0.0680871\ttotal: 36.3s\tremaining: 1m 7s\n",
      "349:\tlearn: 0.0680858\ttotal: 36.4s\tremaining: 1m 7s\n",
      "350:\tlearn: 0.0680850\ttotal: 36.5s\tremaining: 1m 7s\n",
      "351:\tlearn: 0.0680843\ttotal: 36.6s\tremaining: 1m 7s\n",
      "352:\tlearn: 0.0680836\ttotal: 36.7s\tremaining: 1m 7s\n",
      "353:\tlearn: 0.0680829\ttotal: 36.8s\tremaining: 1m 7s\n",
      "354:\tlearn: 0.0680821\ttotal: 36.9s\tremaining: 1m 7s\n",
      "355:\tlearn: 0.0680815\ttotal: 37s\tremaining: 1m 7s\n",
      "356:\tlearn: 0.0680800\ttotal: 37.2s\tremaining: 1m 6s\n",
      "357:\tlearn: 0.0680793\ttotal: 37.3s\tremaining: 1m 6s\n",
      "358:\tlearn: 0.0680784\ttotal: 37.4s\tremaining: 1m 6s\n",
      "359:\tlearn: 0.0680777\ttotal: 37.4s\tremaining: 1m 6s\n",
      "360:\tlearn: 0.0680760\ttotal: 37.5s\tremaining: 1m 6s\n",
      "361:\tlearn: 0.0680751\ttotal: 37.6s\tremaining: 1m 6s\n",
      "362:\tlearn: 0.0680743\ttotal: 37.8s\tremaining: 1m 6s\n",
      "363:\tlearn: 0.0680737\ttotal: 37.9s\tremaining: 1m 6s\n",
      "364:\tlearn: 0.0680731\ttotal: 38s\tremaining: 1m 6s\n",
      "365:\tlearn: 0.0680718\ttotal: 38.1s\tremaining: 1m 5s\n",
      "366:\tlearn: 0.0680705\ttotal: 38.2s\tremaining: 1m 5s\n",
      "367:\tlearn: 0.0680694\ttotal: 38.3s\tremaining: 1m 5s\n",
      "368:\tlearn: 0.0680682\ttotal: 38.4s\tremaining: 1m 5s\n",
      "369:\tlearn: 0.0680664\ttotal: 38.5s\tremaining: 1m 5s\n",
      "370:\tlearn: 0.0680659\ttotal: 38.6s\tremaining: 1m 5s\n",
      "371:\tlearn: 0.0680650\ttotal: 38.7s\tremaining: 1m 5s\n",
      "372:\tlearn: 0.0680637\ttotal: 38.7s\tremaining: 1m 5s\n",
      "373:\tlearn: 0.0680623\ttotal: 38.8s\tremaining: 1m 5s\n",
      "374:\tlearn: 0.0680611\ttotal: 38.9s\tremaining: 1m 4s\n",
      "375:\tlearn: 0.0680598\ttotal: 39s\tremaining: 1m 4s\n",
      "376:\tlearn: 0.0680594\ttotal: 39.1s\tremaining: 1m 4s\n",
      "377:\tlearn: 0.0680585\ttotal: 39.3s\tremaining: 1m 4s\n",
      "378:\tlearn: 0.0680580\ttotal: 39.3s\tremaining: 1m 4s\n",
      "379:\tlearn: 0.0680572\ttotal: 39.4s\tremaining: 1m 4s\n",
      "380:\tlearn: 0.0680565\ttotal: 39.5s\tremaining: 1m 4s\n",
      "381:\tlearn: 0.0680559\ttotal: 39.6s\tremaining: 1m 4s\n",
      "382:\tlearn: 0.0680549\ttotal: 39.7s\tremaining: 1m 3s\n",
      "383:\tlearn: 0.0680539\ttotal: 39.8s\tremaining: 1m 3s\n",
      "384:\tlearn: 0.0680534\ttotal: 39.9s\tremaining: 1m 3s\n",
      "385:\tlearn: 0.0680522\ttotal: 40s\tremaining: 1m 3s\n",
      "386:\tlearn: 0.0680509\ttotal: 40.1s\tremaining: 1m 3s\n",
      "387:\tlearn: 0.0680493\ttotal: 40.2s\tremaining: 1m 3s\n",
      "388:\tlearn: 0.0680488\ttotal: 40.3s\tremaining: 1m 3s\n",
      "389:\tlearn: 0.0680477\ttotal: 40.4s\tremaining: 1m 3s\n",
      "390:\tlearn: 0.0680472\ttotal: 40.5s\tremaining: 1m 3s\n",
      "391:\tlearn: 0.0680460\ttotal: 40.6s\tremaining: 1m 2s\n",
      "392:\tlearn: 0.0680449\ttotal: 40.7s\tremaining: 1m 2s\n",
      "393:\tlearn: 0.0680442\ttotal: 40.8s\tremaining: 1m 2s\n",
      "394:\tlearn: 0.0680434\ttotal: 40.9s\tremaining: 1m 2s\n",
      "395:\tlearn: 0.0680415\ttotal: 41s\tremaining: 1m 2s\n",
      "396:\tlearn: 0.0680409\ttotal: 41.1s\tremaining: 1m 2s\n",
      "397:\tlearn: 0.0680406\ttotal: 41.2s\tremaining: 1m 2s\n",
      "398:\tlearn: 0.0680396\ttotal: 41.3s\tremaining: 1m 2s\n",
      "399:\tlearn: 0.0680391\ttotal: 41.4s\tremaining: 1m 2s\n",
      "400:\tlearn: 0.0680382\ttotal: 41.5s\tremaining: 1m 2s\n",
      "401:\tlearn: 0.0680374\ttotal: 41.6s\tremaining: 1m 1s\n",
      "402:\tlearn: 0.0680367\ttotal: 41.7s\tremaining: 1m 1s\n",
      "403:\tlearn: 0.0680359\ttotal: 41.8s\tremaining: 1m 1s\n",
      "404:\tlearn: 0.0680353\ttotal: 42s\tremaining: 1m 1s\n",
      "405:\tlearn: 0.0680343\ttotal: 42.1s\tremaining: 1m 1s\n",
      "406:\tlearn: 0.0680333\ttotal: 42.2s\tremaining: 1m 1s\n",
      "407:\tlearn: 0.0680326\ttotal: 42.3s\tremaining: 1m 1s\n",
      "408:\tlearn: 0.0680311\ttotal: 42.4s\tremaining: 1m 1s\n",
      "409:\tlearn: 0.0680304\ttotal: 42.5s\tremaining: 1m 1s\n",
      "410:\tlearn: 0.0680288\ttotal: 42.6s\tremaining: 1m 1s\n",
      "411:\tlearn: 0.0680283\ttotal: 42.7s\tremaining: 1m\n",
      "412:\tlearn: 0.0680273\ttotal: 42.8s\tremaining: 1m\n",
      "413:\tlearn: 0.0680269\ttotal: 42.9s\tremaining: 1m\n",
      "414:\tlearn: 0.0680256\ttotal: 43s\tremaining: 1m\n",
      "415:\tlearn: 0.0680243\ttotal: 43.1s\tremaining: 1m\n",
      "416:\tlearn: 0.0680234\ttotal: 43.2s\tremaining: 1m\n",
      "417:\tlearn: 0.0680226\ttotal: 43.3s\tremaining: 1m\n",
      "418:\tlearn: 0.0680216\ttotal: 43.4s\tremaining: 1m\n",
      "419:\tlearn: 0.0680209\ttotal: 43.5s\tremaining: 1m\n",
      "420:\tlearn: 0.0680197\ttotal: 43.6s\tremaining: 60s\n",
      "421:\tlearn: 0.0680191\ttotal: 43.7s\tremaining: 59.8s\n",
      "422:\tlearn: 0.0680176\ttotal: 43.8s\tremaining: 59.7s\n",
      "423:\tlearn: 0.0680167\ttotal: 43.9s\tremaining: 59.6s\n",
      "424:\tlearn: 0.0680157\ttotal: 44s\tremaining: 59.5s\n",
      "425:\tlearn: 0.0680148\ttotal: 44.1s\tremaining: 59.4s\n",
      "426:\tlearn: 0.0680139\ttotal: 44.2s\tremaining: 59.3s\n",
      "427:\tlearn: 0.0680130\ttotal: 44.3s\tremaining: 59.2s\n",
      "428:\tlearn: 0.0680119\ttotal: 44.4s\tremaining: 59.1s\n",
      "429:\tlearn: 0.0680109\ttotal: 44.5s\tremaining: 59s\n",
      "430:\tlearn: 0.0680103\ttotal: 44.6s\tremaining: 58.9s\n",
      "431:\tlearn: 0.0680097\ttotal: 44.7s\tremaining: 58.7s\n",
      "432:\tlearn: 0.0680090\ttotal: 44.8s\tremaining: 58.6s\n",
      "433:\tlearn: 0.0680082\ttotal: 44.9s\tremaining: 58.5s\n",
      "434:\tlearn: 0.0680076\ttotal: 45s\tremaining: 58.4s\n",
      "435:\tlearn: 0.0680067\ttotal: 45.1s\tremaining: 58.3s\n",
      "436:\tlearn: 0.0680061\ttotal: 45.2s\tremaining: 58.2s\n",
      "437:\tlearn: 0.0680052\ttotal: 45.3s\tremaining: 58.1s\n",
      "438:\tlearn: 0.0680046\ttotal: 45.4s\tremaining: 58s\n",
      "439:\tlearn: 0.0680038\ttotal: 45.5s\tremaining: 57.9s\n",
      "440:\tlearn: 0.0680028\ttotal: 45.6s\tremaining: 57.7s\n",
      "441:\tlearn: 0.0680018\ttotal: 45.7s\tremaining: 57.6s\n",
      "442:\tlearn: 0.0680013\ttotal: 45.7s\tremaining: 57.5s\n",
      "443:\tlearn: 0.0680004\ttotal: 45.8s\tremaining: 57.4s\n",
      "444:\tlearn: 0.0679989\ttotal: 45.9s\tremaining: 57.3s\n",
      "445:\tlearn: 0.0679981\ttotal: 46s\tremaining: 57.1s\n",
      "446:\tlearn: 0.0679974\ttotal: 46.1s\tremaining: 57s\n",
      "447:\tlearn: 0.0679965\ttotal: 46.2s\tremaining: 56.9s\n",
      "448:\tlearn: 0.0679955\ttotal: 46.3s\tremaining: 56.8s\n",
      "449:\tlearn: 0.0679948\ttotal: 46.4s\tremaining: 56.7s\n",
      "450:\tlearn: 0.0679936\ttotal: 46.5s\tremaining: 56.6s\n",
      "451:\tlearn: 0.0679927\ttotal: 46.6s\tremaining: 56.5s\n",
      "452:\tlearn: 0.0679917\ttotal: 46.7s\tremaining: 56.4s\n",
      "453:\tlearn: 0.0679909\ttotal: 46.8s\tremaining: 56.3s\n",
      "454:\tlearn: 0.0679897\ttotal: 46.9s\tremaining: 56.2s\n",
      "455:\tlearn: 0.0679891\ttotal: 47s\tremaining: 56s\n",
      "456:\tlearn: 0.0679880\ttotal: 47.1s\tremaining: 55.9s\n",
      "457:\tlearn: 0.0679876\ttotal: 47.2s\tremaining: 55.8s\n",
      "458:\tlearn: 0.0679869\ttotal: 47.3s\tremaining: 55.8s\n",
      "459:\tlearn: 0.0679863\ttotal: 47.4s\tremaining: 55.7s\n",
      "460:\tlearn: 0.0679855\ttotal: 47.5s\tremaining: 55.6s\n",
      "461:\tlearn: 0.0679850\ttotal: 47.6s\tremaining: 55.5s\n",
      "462:\tlearn: 0.0679846\ttotal: 47.7s\tremaining: 55.3s\n",
      "463:\tlearn: 0.0679840\ttotal: 47.8s\tremaining: 55.2s\n",
      "464:\tlearn: 0.0679835\ttotal: 47.9s\tremaining: 55.1s\n",
      "465:\tlearn: 0.0679830\ttotal: 48s\tremaining: 55s\n",
      "466:\tlearn: 0.0679825\ttotal: 48.1s\tremaining: 54.9s\n",
      "467:\tlearn: 0.0679819\ttotal: 48.3s\tremaining: 54.9s\n",
      "468:\tlearn: 0.0679811\ttotal: 48.3s\tremaining: 54.7s\n",
      "469:\tlearn: 0.0679807\ttotal: 48.4s\tremaining: 54.6s\n",
      "470:\tlearn: 0.0679796\ttotal: 48.5s\tremaining: 54.5s\n",
      "471:\tlearn: 0.0679789\ttotal: 48.7s\tremaining: 54.4s\n",
      "472:\tlearn: 0.0679783\ttotal: 48.7s\tremaining: 54.3s\n",
      "473:\tlearn: 0.0679777\ttotal: 48.8s\tremaining: 54.2s\n",
      "474:\tlearn: 0.0679767\ttotal: 48.9s\tremaining: 54.1s\n",
      "475:\tlearn: 0.0679763\ttotal: 49s\tremaining: 54s\n",
      "476:\tlearn: 0.0679760\ttotal: 49.1s\tremaining: 53.8s\n",
      "477:\tlearn: 0.0679751\ttotal: 49.2s\tremaining: 53.7s\n",
      "478:\tlearn: 0.0679736\ttotal: 49.3s\tremaining: 53.6s\n",
      "479:\tlearn: 0.0679730\ttotal: 49.4s\tremaining: 53.5s\n",
      "480:\tlearn: 0.0679723\ttotal: 49.5s\tremaining: 53.4s\n",
      "481:\tlearn: 0.0679707\ttotal: 49.6s\tremaining: 53.3s\n",
      "482:\tlearn: 0.0679698\ttotal: 49.7s\tremaining: 53.2s\n",
      "483:\tlearn: 0.0679688\ttotal: 49.8s\tremaining: 53.1s\n",
      "484:\tlearn: 0.0679680\ttotal: 49.9s\tremaining: 53s\n",
      "485:\tlearn: 0.0679675\ttotal: 50.1s\tremaining: 52.9s\n",
      "486:\tlearn: 0.0679669\ttotal: 50.2s\tremaining: 52.8s\n",
      "487:\tlearn: 0.0679665\ttotal: 50.3s\tremaining: 52.7s\n",
      "488:\tlearn: 0.0679660\ttotal: 50.4s\tremaining: 52.7s\n",
      "489:\tlearn: 0.0679653\ttotal: 50.5s\tremaining: 52.5s\n",
      "490:\tlearn: 0.0679647\ttotal: 50.6s\tremaining: 52.4s\n",
      "491:\tlearn: 0.0679638\ttotal: 50.7s\tremaining: 52.3s\n",
      "492:\tlearn: 0.0679631\ttotal: 50.8s\tremaining: 52.2s\n",
      "493:\tlearn: 0.0679625\ttotal: 50.9s\tremaining: 52.2s\n",
      "494:\tlearn: 0.0679618\ttotal: 51s\tremaining: 52.1s\n",
      "495:\tlearn: 0.0679613\ttotal: 51.1s\tremaining: 52s\n",
      "496:\tlearn: 0.0679606\ttotal: 51.2s\tremaining: 51.8s\n",
      "497:\tlearn: 0.0679602\ttotal: 51.3s\tremaining: 51.8s\n",
      "498:\tlearn: 0.0679594\ttotal: 51.5s\tremaining: 51.7s\n",
      "499:\tlearn: 0.0679591\ttotal: 51.6s\tremaining: 51.6s\n",
      "500:\tlearn: 0.0679587\ttotal: 51.6s\tremaining: 51.4s\n",
      "501:\tlearn: 0.0679578\ttotal: 51.7s\tremaining: 51.3s\n",
      "502:\tlearn: 0.0679572\ttotal: 51.8s\tremaining: 51.2s\n",
      "503:\tlearn: 0.0679565\ttotal: 52s\tremaining: 51.1s\n",
      "504:\tlearn: 0.0679559\ttotal: 52.1s\tremaining: 51s\n",
      "505:\tlearn: 0.0679556\ttotal: 52.2s\tremaining: 50.9s\n",
      "506:\tlearn: 0.0679548\ttotal: 52.3s\tremaining: 50.8s\n",
      "507:\tlearn: 0.0679540\ttotal: 52.4s\tremaining: 50.7s\n",
      "508:\tlearn: 0.0679537\ttotal: 52.5s\tremaining: 50.6s\n",
      "509:\tlearn: 0.0679530\ttotal: 52.6s\tremaining: 50.5s\n",
      "510:\tlearn: 0.0679522\ttotal: 52.7s\tremaining: 50.4s\n",
      "511:\tlearn: 0.0679519\ttotal: 52.8s\tremaining: 50.3s\n",
      "512:\tlearn: 0.0679510\ttotal: 52.9s\tremaining: 50.3s\n",
      "513:\tlearn: 0.0679503\ttotal: 53s\tremaining: 50.1s\n",
      "514:\tlearn: 0.0679494\ttotal: 53.1s\tremaining: 50s\n",
      "515:\tlearn: 0.0679489\ttotal: 53.2s\tremaining: 49.9s\n",
      "516:\tlearn: 0.0679480\ttotal: 53.3s\tremaining: 49.8s\n",
      "517:\tlearn: 0.0679471\ttotal: 53.4s\tremaining: 49.7s\n",
      "518:\tlearn: 0.0679456\ttotal: 53.6s\tremaining: 49.6s\n",
      "519:\tlearn: 0.0679451\ttotal: 53.6s\tremaining: 49.5s\n",
      "520:\tlearn: 0.0679446\ttotal: 53.7s\tremaining: 49.4s\n",
      "521:\tlearn: 0.0679437\ttotal: 53.8s\tremaining: 49.3s\n",
      "522:\tlearn: 0.0679431\ttotal: 53.9s\tremaining: 49.2s\n",
      "523:\tlearn: 0.0679426\ttotal: 54s\tremaining: 49.1s\n",
      "524:\tlearn: 0.0679416\ttotal: 54.1s\tremaining: 49s\n",
      "525:\tlearn: 0.0679407\ttotal: 54.2s\tremaining: 48.9s\n",
      "526:\tlearn: 0.0679403\ttotal: 54.3s\tremaining: 48.8s\n",
      "527:\tlearn: 0.0679391\ttotal: 54.4s\tremaining: 48.7s\n",
      "528:\tlearn: 0.0679383\ttotal: 54.6s\tremaining: 48.6s\n",
      "529:\tlearn: 0.0679376\ttotal: 54.7s\tremaining: 48.5s\n",
      "530:\tlearn: 0.0679370\ttotal: 54.7s\tremaining: 48.4s\n",
      "531:\tlearn: 0.0679362\ttotal: 54.8s\tremaining: 48.2s\n",
      "532:\tlearn: 0.0679349\ttotal: 55s\tremaining: 48.1s\n",
      "533:\tlearn: 0.0679342\ttotal: 55.1s\tremaining: 48s\n",
      "534:\tlearn: 0.0679332\ttotal: 55.2s\tremaining: 47.9s\n",
      "535:\tlearn: 0.0679327\ttotal: 55.2s\tremaining: 47.8s\n",
      "536:\tlearn: 0.0679321\ttotal: 55.4s\tremaining: 47.7s\n",
      "537:\tlearn: 0.0679315\ttotal: 55.5s\tremaining: 47.7s\n",
      "538:\tlearn: 0.0679304\ttotal: 55.6s\tremaining: 47.5s\n",
      "539:\tlearn: 0.0679296\ttotal: 55.7s\tremaining: 47.4s\n",
      "540:\tlearn: 0.0679290\ttotal: 55.8s\tremaining: 47.4s\n",
      "541:\tlearn: 0.0679284\ttotal: 55.9s\tremaining: 47.3s\n",
      "542:\tlearn: 0.0679279\ttotal: 56.1s\tremaining: 47.2s\n",
      "543:\tlearn: 0.0679274\ttotal: 56.2s\tremaining: 47.1s\n",
      "544:\tlearn: 0.0679270\ttotal: 56.3s\tremaining: 47s\n",
      "545:\tlearn: 0.0679267\ttotal: 56.4s\tremaining: 46.9s\n",
      "546:\tlearn: 0.0679261\ttotal: 56.5s\tremaining: 46.8s\n",
      "547:\tlearn: 0.0679256\ttotal: 56.6s\tremaining: 46.7s\n",
      "548:\tlearn: 0.0679251\ttotal: 56.7s\tremaining: 46.6s\n",
      "549:\tlearn: 0.0679244\ttotal: 56.8s\tremaining: 46.5s\n",
      "550:\tlearn: 0.0679238\ttotal: 56.9s\tremaining: 46.4s\n",
      "551:\tlearn: 0.0679232\ttotal: 57s\tremaining: 46.3s\n",
      "552:\tlearn: 0.0679224\ttotal: 57.1s\tremaining: 46.2s\n",
      "553:\tlearn: 0.0679219\ttotal: 57.3s\tremaining: 46.1s\n",
      "554:\tlearn: 0.0679209\ttotal: 57.4s\tremaining: 46s\n",
      "555:\tlearn: 0.0679202\ttotal: 57.5s\tremaining: 45.9s\n",
      "556:\tlearn: 0.0679200\ttotal: 57.6s\tremaining: 45.8s\n",
      "557:\tlearn: 0.0679190\ttotal: 57.7s\tremaining: 45.7s\n",
      "558:\tlearn: 0.0679184\ttotal: 57.9s\tremaining: 45.6s\n",
      "559:\tlearn: 0.0679182\ttotal: 58s\tremaining: 45.5s\n",
      "560:\tlearn: 0.0679177\ttotal: 58.1s\tremaining: 45.5s\n",
      "561:\tlearn: 0.0679170\ttotal: 58.2s\tremaining: 45.4s\n",
      "562:\tlearn: 0.0679166\ttotal: 58.3s\tremaining: 45.3s\n",
      "563:\tlearn: 0.0679157\ttotal: 58.4s\tremaining: 45.1s\n",
      "564:\tlearn: 0.0679151\ttotal: 58.5s\tremaining: 45s\n",
      "565:\tlearn: 0.0679146\ttotal: 58.6s\tremaining: 44.9s\n",
      "566:\tlearn: 0.0679133\ttotal: 58.7s\tremaining: 44.8s\n",
      "567:\tlearn: 0.0679126\ttotal: 58.8s\tremaining: 44.7s\n",
      "568:\tlearn: 0.0679119\ttotal: 58.9s\tremaining: 44.6s\n",
      "569:\tlearn: 0.0679111\ttotal: 59s\tremaining: 44.5s\n",
      "570:\tlearn: 0.0679104\ttotal: 59.1s\tremaining: 44.4s\n",
      "571:\tlearn: 0.0679099\ttotal: 59.2s\tremaining: 44.3s\n",
      "572:\tlearn: 0.0679094\ttotal: 59.3s\tremaining: 44.2s\n",
      "573:\tlearn: 0.0679087\ttotal: 59.4s\tremaining: 44.1s\n",
      "574:\tlearn: 0.0679080\ttotal: 59.5s\tremaining: 44s\n",
      "575:\tlearn: 0.0679073\ttotal: 59.6s\tremaining: 43.9s\n",
      "576:\tlearn: 0.0679069\ttotal: 59.7s\tremaining: 43.8s\n",
      "577:\tlearn: 0.0679063\ttotal: 59.8s\tremaining: 43.7s\n",
      "578:\tlearn: 0.0679059\ttotal: 59.9s\tremaining: 43.6s\n",
      "579:\tlearn: 0.0679054\ttotal: 60s\tremaining: 43.4s\n",
      "580:\tlearn: 0.0679050\ttotal: 1m\tremaining: 43.3s\n",
      "581:\tlearn: 0.0679046\ttotal: 1m\tremaining: 43.2s\n",
      "582:\tlearn: 0.0679042\ttotal: 1m\tremaining: 43.1s\n",
      "583:\tlearn: 0.0679037\ttotal: 1m\tremaining: 43s\n",
      "584:\tlearn: 0.0679030\ttotal: 1m\tremaining: 42.9s\n",
      "585:\tlearn: 0.0679025\ttotal: 1m\tremaining: 42.8s\n",
      "586:\tlearn: 0.0679019\ttotal: 1m\tremaining: 42.7s\n",
      "587:\tlearn: 0.0679014\ttotal: 1m\tremaining: 42.6s\n",
      "588:\tlearn: 0.0679010\ttotal: 1m\tremaining: 42.5s\n",
      "589:\tlearn: 0.0679007\ttotal: 1m\tremaining: 42.4s\n",
      "590:\tlearn: 0.0679004\ttotal: 1m 1s\tremaining: 42.3s\n",
      "591:\tlearn: 0.0678999\ttotal: 1m 1s\tremaining: 42.2s\n",
      "592:\tlearn: 0.0678992\ttotal: 1m 1s\tremaining: 42.1s\n",
      "593:\tlearn: 0.0678986\ttotal: 1m 1s\tremaining: 42s\n",
      "594:\tlearn: 0.0678981\ttotal: 1m 1s\tremaining: 41.8s\n",
      "595:\tlearn: 0.0678975\ttotal: 1m 1s\tremaining: 41.7s\n",
      "596:\tlearn: 0.0678971\ttotal: 1m 1s\tremaining: 41.6s\n",
      "597:\tlearn: 0.0678964\ttotal: 1m 1s\tremaining: 41.5s\n",
      "598:\tlearn: 0.0678957\ttotal: 1m 1s\tremaining: 41.4s\n",
      "599:\tlearn: 0.0678951\ttotal: 1m 1s\tremaining: 41.3s\n",
      "600:\tlearn: 0.0678939\ttotal: 1m 2s\tremaining: 41.2s\n",
      "601:\tlearn: 0.0678933\ttotal: 1m 2s\tremaining: 41.1s\n",
      "602:\tlearn: 0.0678927\ttotal: 1m 2s\tremaining: 41s\n",
      "603:\tlearn: 0.0678918\ttotal: 1m 2s\tremaining: 40.9s\n",
      "604:\tlearn: 0.0678912\ttotal: 1m 2s\tremaining: 40.8s\n",
      "605:\tlearn: 0.0678907\ttotal: 1m 2s\tremaining: 40.7s\n",
      "606:\tlearn: 0.0678900\ttotal: 1m 2s\tremaining: 40.6s\n",
      "607:\tlearn: 0.0678888\ttotal: 1m 2s\tremaining: 40.5s\n",
      "608:\tlearn: 0.0678879\ttotal: 1m 2s\tremaining: 40.4s\n",
      "609:\tlearn: 0.0678871\ttotal: 1m 2s\tremaining: 40.3s\n",
      "610:\tlearn: 0.0678867\ttotal: 1m 3s\tremaining: 40.2s\n",
      "611:\tlearn: 0.0678862\ttotal: 1m 3s\tremaining: 40.1s\n",
      "612:\tlearn: 0.0678856\ttotal: 1m 3s\tremaining: 40s\n",
      "613:\tlearn: 0.0678851\ttotal: 1m 3s\tremaining: 39.9s\n",
      "614:\tlearn: 0.0678839\ttotal: 1m 3s\tremaining: 39.8s\n",
      "615:\tlearn: 0.0678828\ttotal: 1m 3s\tremaining: 39.7s\n",
      "616:\tlearn: 0.0678824\ttotal: 1m 3s\tremaining: 39.5s\n",
      "617:\tlearn: 0.0678818\ttotal: 1m 3s\tremaining: 39.5s\n",
      "618:\tlearn: 0.0678808\ttotal: 1m 3s\tremaining: 39.3s\n",
      "619:\tlearn: 0.0678802\ttotal: 1m 4s\tremaining: 39.2s\n",
      "620:\tlearn: 0.0678798\ttotal: 1m 4s\tremaining: 39.1s\n",
      "621:\tlearn: 0.0678795\ttotal: 1m 4s\tremaining: 39s\n",
      "622:\tlearn: 0.0678786\ttotal: 1m 4s\tremaining: 38.9s\n",
      "623:\tlearn: 0.0678780\ttotal: 1m 4s\tremaining: 38.8s\n",
      "624:\tlearn: 0.0678774\ttotal: 1m 4s\tremaining: 38.7s\n",
      "625:\tlearn: 0.0678770\ttotal: 1m 4s\tremaining: 38.6s\n",
      "626:\tlearn: 0.0678765\ttotal: 1m 4s\tremaining: 38.5s\n",
      "627:\tlearn: 0.0678758\ttotal: 1m 4s\tremaining: 38.4s\n",
      "628:\tlearn: 0.0678739\ttotal: 1m 4s\tremaining: 38.3s\n",
      "629:\tlearn: 0.0678734\ttotal: 1m 5s\tremaining: 38.2s\n",
      "630:\tlearn: 0.0678727\ttotal: 1m 5s\tremaining: 38.1s\n",
      "631:\tlearn: 0.0678721\ttotal: 1m 5s\tremaining: 38s\n",
      "632:\tlearn: 0.0678711\ttotal: 1m 5s\tremaining: 37.9s\n",
      "633:\tlearn: 0.0678706\ttotal: 1m 5s\tremaining: 37.8s\n",
      "634:\tlearn: 0.0678701\ttotal: 1m 5s\tremaining: 37.7s\n",
      "635:\tlearn: 0.0678698\ttotal: 1m 5s\tremaining: 37.6s\n",
      "636:\tlearn: 0.0678693\ttotal: 1m 5s\tremaining: 37.5s\n",
      "637:\tlearn: 0.0678686\ttotal: 1m 5s\tremaining: 37.4s\n",
      "638:\tlearn: 0.0678676\ttotal: 1m 5s\tremaining: 37.3s\n",
      "639:\tlearn: 0.0678666\ttotal: 1m 6s\tremaining: 37.2s\n",
      "640:\tlearn: 0.0678659\ttotal: 1m 6s\tremaining: 37.1s\n",
      "641:\tlearn: 0.0678656\ttotal: 1m 6s\tremaining: 37s\n",
      "642:\tlearn: 0.0678647\ttotal: 1m 6s\tremaining: 36.9s\n",
      "643:\tlearn: 0.0678639\ttotal: 1m 6s\tremaining: 36.8s\n",
      "644:\tlearn: 0.0678633\ttotal: 1m 6s\tremaining: 36.7s\n",
      "645:\tlearn: 0.0678624\ttotal: 1m 6s\tremaining: 36.6s\n",
      "646:\tlearn: 0.0678620\ttotal: 1m 6s\tremaining: 36.5s\n",
      "647:\tlearn: 0.0678616\ttotal: 1m 6s\tremaining: 36.4s\n",
      "648:\tlearn: 0.0678609\ttotal: 1m 7s\tremaining: 36.3s\n",
      "649:\tlearn: 0.0678602\ttotal: 1m 7s\tremaining: 36.2s\n",
      "650:\tlearn: 0.0678595\ttotal: 1m 7s\tremaining: 36.1s\n",
      "651:\tlearn: 0.0678586\ttotal: 1m 7s\tremaining: 36s\n",
      "652:\tlearn: 0.0678578\ttotal: 1m 7s\tremaining: 35.9s\n",
      "653:\tlearn: 0.0678576\ttotal: 1m 7s\tremaining: 35.8s\n",
      "654:\tlearn: 0.0678566\ttotal: 1m 7s\tremaining: 35.6s\n",
      "655:\tlearn: 0.0678557\ttotal: 1m 7s\tremaining: 35.5s\n",
      "656:\tlearn: 0.0678549\ttotal: 1m 7s\tremaining: 35.4s\n",
      "657:\tlearn: 0.0678544\ttotal: 1m 7s\tremaining: 35.3s\n",
      "658:\tlearn: 0.0678540\ttotal: 1m 8s\tremaining: 35.2s\n",
      "659:\tlearn: 0.0678535\ttotal: 1m 8s\tremaining: 35.1s\n",
      "660:\tlearn: 0.0678531\ttotal: 1m 8s\tremaining: 35s\n",
      "661:\tlearn: 0.0678524\ttotal: 1m 8s\tremaining: 34.9s\n",
      "662:\tlearn: 0.0678515\ttotal: 1m 8s\tremaining: 34.8s\n",
      "663:\tlearn: 0.0678508\ttotal: 1m 8s\tremaining: 34.7s\n",
      "664:\tlearn: 0.0678504\ttotal: 1m 8s\tremaining: 34.6s\n",
      "665:\tlearn: 0.0678500\ttotal: 1m 8s\tremaining: 34.5s\n",
      "666:\tlearn: 0.0678496\ttotal: 1m 8s\tremaining: 34.4s\n",
      "667:\tlearn: 0.0678490\ttotal: 1m 8s\tremaining: 34.3s\n",
      "668:\tlearn: 0.0678484\ttotal: 1m 9s\tremaining: 34.2s\n",
      "669:\tlearn: 0.0678479\ttotal: 1m 9s\tremaining: 34s\n",
      "670:\tlearn: 0.0678470\ttotal: 1m 9s\tremaining: 33.9s\n",
      "671:\tlearn: 0.0678463\ttotal: 1m 9s\tremaining: 33.8s\n",
      "672:\tlearn: 0.0678460\ttotal: 1m 9s\tremaining: 33.7s\n",
      "673:\tlearn: 0.0678454\ttotal: 1m 9s\tremaining: 33.6s\n",
      "674:\tlearn: 0.0678445\ttotal: 1m 9s\tremaining: 33.5s\n",
      "675:\tlearn: 0.0678437\ttotal: 1m 9s\tremaining: 33.4s\n",
      "676:\tlearn: 0.0678435\ttotal: 1m 9s\tremaining: 33.3s\n",
      "677:\tlearn: 0.0678428\ttotal: 1m 9s\tremaining: 33.2s\n",
      "678:\tlearn: 0.0678423\ttotal: 1m 9s\tremaining: 33.1s\n",
      "679:\tlearn: 0.0678418\ttotal: 1m 10s\tremaining: 33s\n",
      "680:\tlearn: 0.0678412\ttotal: 1m 10s\tremaining: 32.9s\n",
      "681:\tlearn: 0.0678406\ttotal: 1m 10s\tremaining: 32.8s\n",
      "682:\tlearn: 0.0678397\ttotal: 1m 10s\tremaining: 32.7s\n",
      "683:\tlearn: 0.0678390\ttotal: 1m 10s\tremaining: 32.6s\n",
      "684:\tlearn: 0.0678375\ttotal: 1m 10s\tremaining: 32.5s\n",
      "685:\tlearn: 0.0678368\ttotal: 1m 10s\tremaining: 32.4s\n",
      "686:\tlearn: 0.0678357\ttotal: 1m 10s\tremaining: 32.3s\n",
      "687:\tlearn: 0.0678349\ttotal: 1m 10s\tremaining: 32.2s\n",
      "688:\tlearn: 0.0678340\ttotal: 1m 11s\tremaining: 32.1s\n",
      "689:\tlearn: 0.0678335\ttotal: 1m 11s\tremaining: 32s\n",
      "690:\tlearn: 0.0678327\ttotal: 1m 11s\tremaining: 31.8s\n",
      "691:\tlearn: 0.0678326\ttotal: 1m 11s\tremaining: 31.7s\n",
      "692:\tlearn: 0.0678320\ttotal: 1m 11s\tremaining: 31.6s\n",
      "693:\tlearn: 0.0678315\ttotal: 1m 11s\tremaining: 31.5s\n",
      "694:\tlearn: 0.0678308\ttotal: 1m 11s\tremaining: 31.4s\n",
      "695:\tlearn: 0.0678302\ttotal: 1m 11s\tremaining: 31.3s\n",
      "696:\tlearn: 0.0678300\ttotal: 1m 11s\tremaining: 31.2s\n",
      "697:\tlearn: 0.0678290\ttotal: 1m 11s\tremaining: 31.1s\n",
      "698:\tlearn: 0.0678279\ttotal: 1m 12s\tremaining: 31s\n",
      "699:\tlearn: 0.0678271\ttotal: 1m 12s\tremaining: 30.9s\n",
      "700:\tlearn: 0.0678265\ttotal: 1m 12s\tremaining: 30.8s\n",
      "701:\tlearn: 0.0678259\ttotal: 1m 12s\tremaining: 30.7s\n",
      "702:\tlearn: 0.0678255\ttotal: 1m 12s\tremaining: 30.6s\n",
      "703:\tlearn: 0.0678243\ttotal: 1m 12s\tremaining: 30.5s\n",
      "704:\tlearn: 0.0678232\ttotal: 1m 12s\tremaining: 30.4s\n",
      "705:\tlearn: 0.0678223\ttotal: 1m 12s\tremaining: 30.3s\n",
      "706:\tlearn: 0.0678218\ttotal: 1m 12s\tremaining: 30.2s\n",
      "707:\tlearn: 0.0678208\ttotal: 1m 13s\tremaining: 30.1s\n",
      "708:\tlearn: 0.0678200\ttotal: 1m 13s\tremaining: 30s\n",
      "709:\tlearn: 0.0678195\ttotal: 1m 13s\tremaining: 29.9s\n",
      "710:\tlearn: 0.0678189\ttotal: 1m 13s\tremaining: 29.8s\n",
      "711:\tlearn: 0.0678177\ttotal: 1m 13s\tremaining: 29.7s\n",
      "712:\tlearn: 0.0678171\ttotal: 1m 13s\tremaining: 29.6s\n",
      "713:\tlearn: 0.0678164\ttotal: 1m 13s\tremaining: 29.5s\n",
      "714:\tlearn: 0.0678158\ttotal: 1m 13s\tremaining: 29.4s\n",
      "715:\tlearn: 0.0678158\ttotal: 1m 13s\tremaining: 29.3s\n",
      "716:\tlearn: 0.0678152\ttotal: 1m 13s\tremaining: 29.2s\n",
      "717:\tlearn: 0.0678149\ttotal: 1m 14s\tremaining: 29.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lewkh\\Documents\\GitHub\\CE4041_ML\\catboost_lightgbm_stack.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart training model \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m CatBoostRegressor(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     loss_function\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     eval_metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMAE\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(catboost_X, catboost_y, cat_features\u001b[39m=\u001b[39;49mcategorical_indices, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Lewkh/Documents/GitHub/CE4041_ML/catboost_lightgbm_stack.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m models\u001b[39m.\u001b[39mappend(model)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2320\u001b[0m         train_pool,\n\u001b[0;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2322\u001b[0m         params,\n\u001b[0;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2325\u001b[0m     )\n\u001b[0;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\catboost\\core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train multiple models\n",
    "rounds = 8\n",
    "models = []\n",
    "for i in range(rounds):\n",
    "    print(\"Start training model {}\".format(i))\n",
    "    model = CatBoostRegressor(\n",
    "        loss_function=\"MAE\",\n",
    "        eval_metric=\"MAE\",\n",
    "        nan_mode=\"Min\",\n",
    "        random_seed=99,\n",
    "        iterations=1000,\n",
    "        learning_rate=0.015,\n",
    "        border_count=254,\n",
    "        max_depth=6,\n",
    "        random_strength=1,\n",
    "        l2_leaf_reg=5,\n",
    "        bagging_temperature=1,\n",
    "        verbose=True,\n",
    "    )\n",
    "    model.fit(catboost_X, catboost_y, cat_features=categorical_indices, verbose=True)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and export results\n",
    "file_name = 'submission/final_catboost_ensemble_x4.csv'\n",
    "submission, pred_2016, pred_2017 = ut.predict_and_generate_csv(models, prop_2016, prop_2017, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop not useful columns\n",
    "lightgbm_features = ut.drop_features(train)\n",
    "print(\"Number of features for Lightgbm: {}\".format(len(lightgbm_features.columns)))\n",
    "lightgbm_features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and cross-validation data\n",
    "lightgbm_label = train.logerror.astype(np.float32)\n",
    "print(lightgbm_label.head())\n",
    "\n",
    "# Transform to Numpy matrices\n",
    "lightgbm_X = lightgbm_features.values\n",
    "lightgbm_y = lightgbm_label.values\n",
    "\n",
    "# Perform shuffled train/test split\n",
    "np.random.seed(42)\n",
    "random.seed(10)\n",
    "X_train, X_val, y_train, y_val = train_test_split(lightgbm_X, lightgbm_y, test_size=0.2 , random_state=99)\n",
    "\n",
    "a,b=ut.remove_outliers(X_train, y_train)\n",
    "X_train=a\n",
    "y_train=b\n",
    "\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_val shape: {}\".format(X_val.shape))\n",
    "print(\"y_val shape: {}\".format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify feature names and categorical features for Lightgbm\n",
    "categorical_features = ['airconditioningtypeid', 'heatingorsystemtypeid', 'propertylandusetypeid', 'year', 'month', 'quarter','buildingclasstypeid']\n",
    "categorical_indices = ut.get_categorical_indices(lightgbm_features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightgbm parameters\n",
    "params = {}\n",
    "\n",
    "params[\"objective\"] = \"regression\"\n",
    "params[\"metric\"] = \"mae\"\n",
    "params[\"num_threads\"] = 4  # set to number of real CPU cores for best performance\n",
    "\n",
    "params[\"boosting_type\"] = \"gbdt\"\n",
    "params[\"num_boost_round\"] = 1250\n",
    "params[\"learning_rate\"] = 0.003  # shrinkage_rate \n",
    "# params[\"early_stopping_rounds\"] = 30  # Early stopping based on validation set performance \n",
    "\n",
    "# Control tree growing\n",
    "params[\"num_leaves\"] = 127  # max number of leaves in one tree (default 31)\n",
    "params[\"min_data\"] = 150  # min_data_in_leaf\n",
    "params[\"min_hessian\"] = 0.001  # min_sum_hessian_in_leaf (default 1e-3)\n",
    "params[\"max_depth\"] = -1  # limit the max depth of tree model, defult -1 (no limit)\n",
    "params[\n",
    "    \"max_bin\"\n",
    "] = 255  # max number of bins that feature values are bucketed in (small -> less overfitting, default 255)\n",
    "params[\n",
    "    \"sub_feature\"\n",
    "] = 0.5  # feature_fraction (small values => use very different submodels)\n",
    "\n",
    "# Row subsampling (speed up training and alleviate overfitting)\n",
    "params[\"bagging_fraction\"] = 0.7\n",
    "params[\"bagging_freq\"] = 50  # perform bagging at every k iteration\n",
    "\n",
    "# Constraints on categorical features\n",
    "params[\n",
    "    \"min_data_per_group\"\n",
    "] = 100  # minimal number of data per categorical group (default 100)\n",
    "params[\n",
    "    \"cat_smooth\"\n",
    "] = 15.0  # reduce effect of noises in categorical features, especially for those with few data (default 10.0)\n",
    "\n",
    "# Regularization (default 0.0)\n",
    "params[\"lambda_l1\"] = 0.0\n",
    "params[\"lambda_l2\"] = 0.0\n",
    "\n",
    "# Random seeds (keep default values)\n",
    "params[\"feature_fraction_seed\"] = 2\n",
    "params[\"bagging_seed\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm Single Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Lightgbm\n",
    "feature_names = [s for s in lightgbm_features.columns]\n",
    "lgb_train_set = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)\n",
    "lgb_valid_set = lgb.Dataset(X_val, label=y_val, feature_name=feature_names)\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(36)\n",
    "model = lgb.train(params, lgb_train_set,\n",
    "                valid_sets=[lgb_train_set, lgb_valid_set], valid_names=['train', 'val'],\n",
    "                categorical_feature=categorical_indices)\n",
    "\n",
    "# Evaluate on train and validation sets\n",
    "print(\"Train score: {}\".format(abs(model.predict(X_train) - y_train).mean() * 100))\n",
    "print(\"Val score: {}\".format(abs(model.predict(X_val) - y_val).mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot LightGBM feature importance\n",
    "lgb.plot_importance(model, height=0.8, figsize=(12.5, 12.5), ignore_zero=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM on all given training data (preparing for submission)\n",
    "#del params['early_stopping_rounds']\n",
    "\n",
    "a,b=ut.remove_outliers(lightgbm_X,lightgbm_y)\n",
    "lightgbm_X=a\n",
    "lightgbm_y=b\n",
    "\n",
    "lgb_train_set = lgb.Dataset(lightgbm_X, label=lightgbm_y, feature_name=feature_names)\n",
    "print(\"lightgbm_X: {}\".format(lightgbm_X.shape))\n",
    "print(\"lightgbm_y: {}\".format(lightgbm_y.shape))\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(36)\n",
    "model = lgb.train(params, lgb_train_set, categorical_feature=categorical_indices)\n",
    "\n",
    "# Sanity check: make sure the model score is reasonable on a small portion of the data\n",
    "print(\"score: {}\".format(abs(model.predict(X_val) - y_val).mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'submission/final_lgb_single.csv'\n",
    "submission, pred_2016, pred_2017 = ut.predict_and_generate_csv([model], prop_2016, prop_2017, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm Ensemble 5x Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=ut.remove_outliers(lightgbm_X,lightgbm_y)\n",
    "lightgbm_X=a\n",
    "lightgbm_y=b\n",
    "\n",
    "lgb_train_set = lgb.Dataset(lightgbm_X, label=lightgbm_y, feature_name=feature_names)\n",
    "\n",
    "# Train multiple models\n",
    "bags = 5\n",
    "models = []\n",
    "for i in range(bags):\n",
    "    print(\"Start training model {}\".format(i))\n",
    "    params[\"seed\"] = i\n",
    "    np.random.seed(42)\n",
    "    random.seed(36)\n",
    "    model = lgb.train(params, lgb_train_set, categorical_feature=categorical_indices)\n",
    "    models.append(model)\n",
    "\n",
    "# Sanity check (make sure scores on a small portion of the dataset are reasonable)\n",
    "for i, model in enumerate(models):\n",
    "    print(\"model {}: {}\".format(i, abs(model.predict(X_val) - y_val).mean() * 100))\n",
    "\n",
    "# Save the trained models to disk\n",
    "ut.save_models(models,'lightgbm')\n",
    "\n",
    "models = ut.load_lightgbm_models(['checkpoints/lightgbm_' + str(i) for i in range(bags)])  # load pretrained models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and export results\n",
    "file_name = 'submission/final_lgb_ensemble_x5.csv'\n",
    "submission, pred_2016, pred_2017 = ut.predict_and_generate_csv(models, prop_2016, prop_2017, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_single = pd.read_csv('submission/final_lgb_single.csv')\n",
    "catboost_single = pd.read_csv('submission/final_catboost_single.csv')\n",
    "print(\"Finished Loading the prediction results.\")\n",
    "\n",
    "def decimal_range(start, stop, increment):\n",
    "    while start <= stop: \n",
    "        yield start\n",
    "        start += increment\n",
    "\n",
    "for weight in decimal_range(0.1, 0.9, 0.1):\n",
    "    #weight = 0.7\n",
    "    stack = pd.DataFrame()\n",
    "    stack[\"ParcelId\"] = lgb_single[\"ParcelId\"]\n",
    "    for col in [\"201610\", \"201611\", \"201612\", \"201710\", \"201711\", \"201712\"]:\n",
    "        stack[col] = weight * catboost_single[col] + (1 - weight) * lgb_single[col]\n",
    "\n",
    "    print(stack.head())\n",
    "    #stack.to_csv(\"submission/final_stack.csv\", index=False)\n",
    "    stack.to_csv(\"submission/final_stack_catboostweight_\" + str(\"{:.1f}\".format(weight)) + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
