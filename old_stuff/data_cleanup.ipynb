{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc #garbage collector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import json\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\") # allow module discovery in parent directory\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from helper import utility\n",
    "from helper.utility import NACellFillers\n",
    "\n",
    "import importlib\n",
    "importlib.reload(utility)\n",
    "\n",
    "DATA_LOC: str = \"../data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Zillow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data set provided\n",
    "prop_2016 = utility.load_data(f'{DATA_LOC}/properties_2016.csv')\n",
    "prop_2017 = utility.load_data(f'{DATA_LOC}/properties_2017.csv')\n",
    "train_2016 = utility.load_data(f'{DATA_LOC}/train_2016_v2.csv' , ['transactiondate'])\n",
    "train_2017 = utility.load_data(f'{DATA_LOC}/train_2017.csv', ['transactiondate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the prop dataset with its corresponding train datasets on their parcelid\n",
    "# left join is used so that all properties without logerror will be ignored\n",
    "training_2016 = utility.merge_data(train_2016, prop_2016, 'parcelid')\n",
    "training_2017 = utility.merge_data(train_2017, prop_2017, 'parcelid')\n",
    "\n",
    "\n",
    "\n",
    "# Data across the 2 years are combined into one data frame for processing at later stages\n",
    "training_all = pd.concat([training_2016, training_2017] , ignore_index=True)\n",
    "properties_all = pd.concat([prop_2016, prop_2017], ignore_index=True)\n",
    "\n",
    "\n",
    "training_all\n",
    "#properties_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and Drop any duplicates in the training dataset\n",
    "# Duplicates are those which have the same parcelid and transactiondate\n",
    "\n",
    "training_all.shape\n",
    "utility.check_duplicates(training_all)\n",
    "training_all = utility.drop_dups(training_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that there are no duplicates in the dataset so far\n",
    "training_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the Target Variable - logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y = training_all['logerror']\n",
    "\n",
    "\n",
    "target_y.hist(bins=50, figsize=(8,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers that are more than 2.5 std away from mean\n",
    "upper_threshold = target_y.mean() + (2.5*target_y.std())\n",
    "lower_threshold = target_y.mean() - (2.5*target_y.std())\n",
    "\n",
    "\n",
    "# Remove data that have their target y value as outliers\n",
    "training_all = training_all[training_all['logerror'] < upper_threshold]\n",
    "training_all = training_all[training_all['logerror'] > lower_threshold]\n",
    "training_all.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Feature to the dataset\n",
    "# Add Day, Month, Year and which quarter the transaction was done\n",
    "training_all = utility.add_dmy_feature(training_all)\n",
    "training_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility.print_percent_missing(training_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that have missing threashold greater than 95%\n",
    "MISSING_THRESHOLD = 0.97\n",
    "col_to_drop = utility.get_col_to_drop_missing(training_all, 0.95)\n",
    "col_to_drop += utility.get_col_to_drop_non_unique(training_all)\n",
    "\n",
    "# Other columns to exlude to prepare for training dataset\n",
    "exclude_list = [\"parcelid\" , \"logerror\" , 'propertyzoningdesc']\n",
    "\n",
    "remaining_col = []\n",
    "for col in training_all.columns:\n",
    "    if col not in col_to_drop and col not in exclude_list:\n",
    "        remaining_col.append(col)\n",
    "        print(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Categorical Values\n",
    "# Convert categorical values to 'category' type for some columns\n",
    "\n",
    "categorylist = ['airconditioningtypeid', 'architecturalstyletypeid', 'buildingclasstypeid',\n",
    "                'buildingqualitytypeid', 'fips', 'heatingorsystemtypeid' ,\n",
    "                'propertylandusetypeid', 'regionidcity', 'regionidcounty',\n",
    "                'regionidneighborhood', 'storytypeid', 'typeconstructiontypeid']\n",
    "\n",
    "for col in training_all.columns:\n",
    "    if col in categorylist:\n",
    "        utility.float_to_categorical(training_all, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert float64 values to float32 values\n",
    "for col in training_all.columns:\n",
    "    if training_all[col].dtype.name == 'float64':\n",
    "        training_all[col] = training_all[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate NA values\n",
    "training_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cols that contain NA cells\n",
    "na_df = training_all.isna()\n",
    "na_cols: pd.Series = na_df.any()\n",
    "cols_with_na: list = na_cols[na_cols == True].index.tolist()\n",
    "\n",
    "df_with_na = training_all[[*cols_with_na]]\n",
    "df_with_na.info()\n",
    "\n",
    "total = len(training_all)\n",
    "\n",
    "#\n",
    "if True:\n",
    "    for col in df_with_na.columns:\n",
    "        ser = df_with_na[col]\n",
    "        non_null = ser.notna().sum()\n",
    "\n",
    "        try:\n",
    "            plt.title(f\"{col}, non-null: {non_null}/{total}\")\n",
    "            sns.violinplot(ser)\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            plt.cla()\n",
    "            plt.clf()\n",
    "            print(f\"unable to plot for {col}: {e}, trying catplot\")\n",
    "            res = ser.value_counts().sort_values(ascending=False)\n",
    "\n",
    "            plt.figure(figsize=(10, len(res)/5))\n",
    "            plt.title(f\"{col}, non-null: {non_null}/{total}\")\n",
    "            sns.barplot(x=res.tolist(), y=res.index)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop even more cols\n",
    "# some cols have very few entries that are filled\n",
    "# AND they do not contribute meaningful information\n",
    "# these are dropped here\n",
    "\n",
    "res = training_all.drop(\n",
    "    columns=[\n",
    "        # \"decktypeid\", # insufficient values; all the same\n",
    "        \"finishedsquarefeet15\", # too little values\n",
    "        \"finishedsquarefeet13\", # too little values\n",
    "        \"finishedsquarefeet6\",\n",
    "        \"finishedsquarefeet50\", # same as above\n",
    "\n",
    "        \"propertycountylandusecode\",    # weird distribution of categories\n",
    "        \"propertyzoningdesc\",           # same as above\n",
    "\n",
    "        \"assessmentyear\",\n",
    "        \"landtaxvaluedollarcnt\",\n",
    "        \"taxamount\",\n",
    "        \"taxdelinquencyflag\",\n",
    "        \"taxdelinquencyyear\",\n",
    "        \"censustractandblock\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_all = res\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing a Series to fill main dataframe\n",
    "\n",
    "# create na_cols again from dropped dataframe\n",
    "na_cols = training_all.isna().any()\n",
    "cols_with_na: list = na_cols[na_cols == True].index.tolist()\n",
    "\n",
    "\n",
    "fill_series: pd.Series = pd.Series(index=cols_with_na)\n",
    "\n",
    "fill_series[\"basementsqft\"] = 0 # no basement\n",
    "fill_series[\"bathroomcnt\"] = NACellFillers.mode(training_all[\"bathroomcnt\"])\n",
    "fill_series[\"bedroomcnt\"] = NACellFillers.mode(training_all[\"bedroomcnt\"])\n",
    "fill_series[\"calculatedbathnbr\"] = NACellFillers.mode(training_all[\"calculatedbathnbr\"])\n",
    "fill_series[\"decktypeid\"] = NACellFillers.mode(training_all[\"decktypeid\"])\n",
    "fill_series[\"finishedfloor1squarefeet\"] = NACellFillers.median(training_all[\"finishedfloor1squarefeet\"])\n",
    "fill_series[\"calculatedfinishedsquarefeet\"] = NACellFillers.median(training_all[\"calculatedfinishedsquarefeet\"])\n",
    "fill_series[\"finishedsquarefeet12\"] = NACellFillers.median(training_all[\"finishedsquarefeet12\"])\n",
    "# fill_series[\"finishedsquarefeet13\"] = 0 # perimeter of living area (???)\n",
    "# fill_series[\"finishedsquarefeet15\"] = NACellFillers.median(training_all[\"finishedsquarefeet15\"])\n",
    "# fill_series[\"finishedsquarefeet50\"] = NACellFillers.median(training_all[\"finishedsquarefeet50\"])\n",
    "fill_series[\"finishedsquarefeet6\"] = 0 # base unfinished and finished area\n",
    "fill_series[\"fireplacecnt\"] = 0 # assume the rest do not have fireplaces\n",
    "fill_series[\"fullbathcnt\"] = NACellFillers.mode(training_all[\"fullbathcnt\"])\n",
    "fill_series[\"garagecarcnt\"] = 0 # assume the rest do not have garages\n",
    "fill_series[\"garagetotalsqft\"] = 0 # same as above\n",
    "fill_series[\"hashottuborspa\"] = 0 # assume the rest do not have hot tubs/spa\n",
    "fill_series[\"latitude\"] = 0     # will be derived from their zip codes\n",
    "fill_series[\"longitude\"] = 0    # will be derived from their zip codes\n",
    "fill_series[\"lotsizesquarefeet\"] = NACellFillers.median(training_all[\"lotsizesquarefeet\"])\n",
    "fill_series[\"poolcnt\"] = 0          # assume the rest do not have pools\n",
    "fill_series[\"poolsizesum\"] = 0      # same as above\n",
    "fill_series[\"pooltypeid10\"] = 0     # same\n",
    "fill_series[\"pooltypeid2\"] = 0      # same\n",
    "fill_series[\"pooltypeid7\"] = 0      # same\n",
    "# fill_series[\"propertycountylandusecode\"] = 0    # text cat, need to encode or something\n",
    "# fill_series[\"propertyzoningdesc\"] = 0           # text cat, need to encode or something\n",
    "fill_series[\"rawcensustractandblock\"] = NACellFillers.median(training_all[\"rawcensustractandblock\"])\n",
    "fill_series[\"regionidzip\"] = 0  # will be derived from coordinates\n",
    "fill_series[\"roomcnt\"] = NACellFillers.mode(training_all[\"roomcnt\"])\n",
    "fill_series[\"threequarterbathnbr\"] = 0 # assume home does not have 3/4 bathroom\n",
    "fill_series[\"unitcnt\"] = NACellFillers.mode(training_all[\"unitcnt\"])\n",
    "fill_series[\"yardbuildingsqft17\"] = 0 # assume the rest do not have patios\n",
    "fill_series[\"yardbuildingsqft26\"] = 0 # assume the rest do not have storage shed/buiding\n",
    "fill_series[\"yearbuilt\"] = NACellFillers.median(training_all[\"yearbuilt\"])\n",
    "fill_series[\"numberofstories\"] = NACellFillers.mode(training_all[\"numberofstories\"])\n",
    "fill_series[\"fireplaceflag\"] = 0 # assume the rest do not have fireplaces\n",
    "fill_series[\"structuretaxvaluedollarcnt\"] = 0 # very little samples\n",
    "fill_series[\"taxvaluedollarcnt\"] = NACellFillers.median(training_all[\"taxvaluedollarcnt\"])\n",
    "# fill_series[\"assessmentyear\"] = 0 # these should have been filled up already\n",
    "# fill_series[\"landtaxvaluedollarcnt\"] = NACellFillers.median(training_all[\"landtaxvaluedollarcnt\"])\n",
    "# fill_series[\"taxamount\"] = NACellFillers.median(training_all[\"taxamount\"])\n",
    "# fill_series[\"taxdelinquencyflag\"] = 0   # related to the two below\n",
    "# fill_series[\"taxdelinquencyyear\"] = 0   #\n",
    "# fill_series[\"censustractandblock\"] = 0  #\n",
    "\n",
    "# save fill data\n",
    "fill_series.to_json(f\"{DATA_LOC}/na_fill_data.json\", indent=4)\n",
    "\n",
    "print(\"NA cell fill data:\", end=\"\\n\\n\")\n",
    "print(fill_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latlong data\n",
    "na_zip = training_all[training_all[\"regionidzip\"].isna()]\n",
    "na_lat = training_all[training_all[\"latitude\"].isna()]\n",
    "na_lon = training_all[training_all[\"longitude\"].isna()]\n",
    "\n",
    "s_zip = set(na_zip.index.tolist())\n",
    "s_lat = set(na_lat.index.tolist())\n",
    "s_lon = set(na_lon.index.tolist())\n",
    "\n",
    "# indices with no lat, lon or zip code\n",
    "i_all_na = s_zip.intersection(s_lon)\n",
    "\n",
    "print(len(i_all_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indices\n",
    "res: pd.DataFrame = training_all.drop(index=i_all_na)\n",
    "\n",
    "# replace NA\n",
    "res = res.fillna(fill_series)\n",
    "\n",
    "res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some cells contain \"True\" instead of 1\n",
    "for col in res.columns:\n",
    "    continue\n",
    "\n",
    "# gather the cols with not-co-clean data (the col dtype shows as 'object')\n",
    "unclean_cols: list = []\n",
    "for idx, typ in enumerate(res.dtypes):\n",
    "    if typ == object:\n",
    "        print(\"ahhh objet\")\n",
    "        unclean_cols.append(res.dtypes.index[idx])\n",
    "\n",
    "print(unclean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = res['hashottuborspa']\n",
    "\n",
    "def strbool_to_float(col: pd.Series):\n",
    "    '''Maps a bool string to float with the following rule:\n",
    "    - \"True\" => 1.0f\n",
    "    - \"False\" => 0.0f\n",
    "    - _ => 0.0f\n",
    "    '''\n",
    "    for idx in range(len(col)):\n",
    "        if not isinstance(col[idx], float) \\\n",
    "            and isinstance(col[idx], str):\n",
    "\n",
    "                if col[idx] == \"True\":\n",
    "                    col[idx] = float(1.0)\n",
    "                else:\n",
    "                    col[idx] = 0.0\n",
    "\n",
    "        else:\n",
    "            col[idx] = 0.0\n",
    "\n",
    "    return\n",
    "\n",
    "for col_name in unclean_cols:\n",
    "    strbool_to_float(res[col_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "res.to_csv(f\"{DATA_LOC}/train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
